{
    "@graph": [
        {
            "@id": "gnd:1310504415",
            "sameAs": "Upadhyay, Uddeshya"
        },
        {
            "@id": "gnd:36187-2",
            "sameAs": "Eberhard Karls Universit\u00e4t T\u00fcbingen"
        },
        {
            "@id": "https://www.tib.eu/de/suchen/id/TIBKAT%3A1870649702",
            "@type": "bibo:Thesis",
            "P1053": "1 Online-Ressource (xv, 117 Seiten)",
            "description": "Illustrationen",
            "identifier": [
                "(firstid)KXP:1870649702",
                "(ppn)1870649702",
                "(doi)10.15496/publikation-89129"
            ],
            "subject": [
                "Maschinelles Lernen",
                "K\u00fcnstliche Intelligenz",
                "Maschinelles Sehen",
                "Unsicherheitsquantifizierung",
                "(classificationName=linseach:mapping)inf",
                "(classificationName=ddc-dbn)004"
            ],
            "title": "Unveiling the ace in the hole : leveraging uncertainty quantification for computer vision systems",
            "abstract": "As machine learning systems become increasingly complex and autonomous, the integration of uncertainty quantification becomes crucial, especially in high-stakes domains like healthcare and autonomous driving, where ambiguity can lead to severe consequences. By offering a clear gauge of prediction confidence, uncertainty quantification supports informed decision-making and risk management. Within the realm of healthcare, where diagnostic procedures often depend on var- ious imaging modalities, modern machine-learning methods are being harnessed to aid diagnosis. Current advancements in generative machine learning explore the synthesis of different medical imaging modalities, predominantly through image-to-image translations. Our work demonstrates that integrating aleatoric uncertainty in Generative Adversarial Networks (GANs) for these translation tasks can amplify interpretability and accuracy. Consequently, this empowers healthcare professionals with better diagnostic and treatment decisions, thus enhancing patient outcomes. In the context of autonomous driving and similar applications, ensuring resilience to unforeseen perturbations is vital. Traditional deterministic models may falter when confronted with new situations, constituting a safety hazard. We address this by implementing a probabilistic approach to dense computer vision tasks and utilizing the Likelihood Annealing technique for uncertainty estimation. These methods amplify the robustness to unexpected situations and provide a calibrated uncertainty measure, contributing to the development of safer autonomous systems. While creating new probabilistic machine learning solutions for vital applications is a key research area, it\u2019s equally significant to develop methods that leverage large-scale pretrained models. These deterministic models can be adapted to estimate uncertainties in a cost-efficient manner regarding data, computation, and other resources, a direction we explore in this thesis. The work presented herein addresses this issue within the context of current computer vision systems, including large-scale vision language models crucial for enabling intelligent multimodal systems.",
            "contributor": "Technische Informationsbibliothek (TIB)",
            "creator": [
                "gnd:36187-2",
                "gnd:1310504415"
            ],
            "isPartOf": "(collectioncode)GBV-ODiss",
            "issued": "2023",
            "language": "http://id.loc.gov/vocabulary/iso639-1/en",
            "license": "open access",
            "medium": "rda:termList/RDACarrierType/1018",
            "isLike": "doi:10.15496/publikation-89129",
            "P60163": "T\u00fcbingen"
        }
    ],
    "@id": "urn:x-arq:DefaultGraphNode",
    "@context": {
        "sameAs": "http://www.w3.org/2002/07/owl#sameAs",
        "isPartOf": "http://purl.org/dc/terms/isPartOf",
        "identifier": "http://purl.org/dc/elements/1.1/identifier",
        "medium": {
            "@id": "http://purl.org/dc/terms/medium",
            "@type": "@id"
        },
        "isLike": {
            "@id": "http://umbel.org/umbel#isLike",
            "@type": "@id"
        },
        "P1053": "http://iflastandards.info/ns/isbd/elements/P1053",
        "subject": "http://purl.org/dc/elements/1.1/subject",
        "contributor": "http://purl.org/dc/terms/contributor",
        "abstract": "http://purl.org/dc/terms/abstract",
        "license": "http://purl.org/dc/terms/license",
        "creator": {
            "@id": "http://purl.org/dc/terms/creator",
            "@type": "@id"
        },
        "language": {
            "@id": "http://purl.org/dc/terms/language",
            "@type": "@id"
        },
        "issued": "http://purl.org/dc/terms/issued",
        "title": "http://purl.org/dc/elements/1.1/title",
        "description": "http://purl.org/dc/elements/1.1/description",
        "P60163": "http://www.rdaregistry.info/Elements/u/#P60163",
        "umbel": "http://umbel.org/umbel#",
        "rdau": "http://www.rdaregistry.info/Elements/u/#",
        "owl": "http://www.w3.org/2002/07/owl#",
        "dcterms": "http://purl.org/dc/terms/",
        "bibo": "http://purl.org/ontology/bibo/",
        "rdam": "http://www.rdaregistry.info/Elements/m/#",
        "gnd": "http://d-nb.info/gnd/",
        "isbd": "http://iflastandards.info/ns/isbd/elements/",
        "rda": "http://rdvocab.info/",
        "doi": "https://doi.org/"
    }
}