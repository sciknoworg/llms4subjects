{
    "@graph": [
        {
            "@id": "gnd:1325178489",
            "sameAs": "Strecke, Michael Felix"
        },
        {
            "@id": "gnd:36187-2",
            "sameAs": "Eberhard Karls Universit\u00e4t T\u00fcbingen"
        },
        {
            "@id": "https://www.tib.eu/de/suchen/id/TIBKAT%3A1884941125",
            "@type": "bibo:Thesis",
            "P1053": "1 Online-Ressource (xx, 109 Seiten)",
            "description": "Illustrationen",
            "identifier": [
                "(doi)10.15496/publikation-93808",
                "(firstid)KXP:1884941125",
                "(ppn)1884941125"
            ],
            "subject": [
                "(classificationName=linseach:mapping)inf",
                "(classificationName=ddc-dbn)004",
                "K\u00fcnstliche Intelligenz",
                "Maschinelles Sehen",
                "(classificationName=ddc-dbn)006.37",
                "Maschinelles Lernen"
            ],
            "title": "Object-level dynamic scene reconstruction with physical plausibility from RGB-D images",
            "abstract": [
                "Humans have the remarkable ability to perceive and interact with objects in the world around them. They can easily segment objects from visual data and have an intuitive understanding of how physics influences objects. By contrast, robots are so far often constrained to tailored environments for a specific task, due to their inability to reconstruct a versatile and accurate scene representation. In this thesis, we combine RGB-D video data with background knowledge of real-world physics to develop such a representation for robots. Our contributions can be separated into two main parts: a dynamic object tracking tool and optimization frameworks that allow for improving shape reconstructions based on physical plausibility. The dynamic object tracking tool \"EM-Fusion\" detects, segments, reconstructs, and tracks objects from RGB-D video data. We propose a probabilistic data association approach for attributing the image pixels to the different moving objects in the scene. This allows us to track and reconstruct moving objects and the background scene with state-of-the art accuracy and robustness towards occlusions. We investigate two ways of further optimizing the reconstructed shapes of moving objects based on physical plausibility. The first of these, \"Co-Section\", includes physical plausibility by reasoning about the empty space around an object. We observe that no two objects can occupy the same space at the same time and that the depth images in the input video provide an estimate of observed empty space. Based on these observations, we propose intersection and hull constraints, which we combine with the observed surfaces in a global optimization approach. Compared to EM-Fusion, which only reconstructs the observed surface, Co-Section optimizes watertight shapes. These watertight shapes provide a rough estimate of unseen surfaces and could be useful as initialization for further refinement, e.g., by interactive perception. In the second optimization approach, \"DiffSDFSim\", we reason about object shapes based on physically plausible object motion. We observe that object trajectories after collisions depend on the object's shape, and extend a differentiable physics simulation for optimizing object shapes together with other physical properties (e.g., forces, masses, friction) based on the motion of the objects and their interactions. Our key contributions are using signed distance function models for representing shapes and a novel method for computing gradients that models the dependency of the time of contact on object shapes. We demonstrate that our approach recovers target shapes well by fitting to target trajectories and depth observations. Further, the ground-truth trajectories are recovered well in simulation using the resulting shape and physical properties. This enables predictions about the future motion of objects by physical simulation. We anticipate that our contributions can be useful building blocks in the development of 3D environment perception for robots. The reconstruction of individual objects as in EM-Fusion is a key ingredient required for interactions with objects. Completed shapes as the ones provided by Co-Section provide useful cues for planning interactions like grasping of objects. Finally, the recovery of shape and other physical parameters using differentiable simulation as in DiffSDFSim allows simulating objects and thus predicting the effects of interactions. Future work might extend the presented works for interactive perception of dynamic environments by comparing these predictions with observed real-world interactions to further improve the reconstructions and physical parameter estimations.",
                "Menschen haben die bemerkenswerte F\u00e4higkeit, Objekte in ihrer Umgebung wahrzunehmen und mit ihnen zu interagieren. Sie k\u00f6nnen ohne Anstrengung Objekte in visuellen Daten segmentieren und haben ein intuitives Verst\u00e4ndnis davon, wie die Physik Objekte beeinflusst. Im Gegensatz dazu sind Roboter bisher oft auf aufgabenspezifisch zugeschnittene Umgebungen begrenzt, da sie keine vielseitige und genaue Szenenrepr\u00e4sentation rekonstruieren k\u00f6nnen. In dieser Dissertation kombinieren wir RGB-D Videodaten mit Hintergrundwissen \u00fcber die Physik der realen Welt, um eine solche Repr\u00e4sentation f\u00fcr Roboter zu entwickeln. Unsere Beitr\u00e4ge bestehen aus zwei Hauptbestandteilen: ein Werkzeug zur Verfolgung bewegter Objekte, und Optimierungsans\u00e4tze, welche Rekonstruktionen der 3D Form basierend auf physikalischer Plausibilit\u00e4t verbessern k\u00f6nnen. Das Werkzeug zur Verfolgung bewegter Objekte, \"EM-Fusion\", detektiert, segmentiert, rekonstruiert und verfolgt Objekte in RGB-D Videodaten. Wir schlagen einen probabilistischen Datenassoziationsansatz vor, um die Pixel im Bild den unterschiedlichen bewegten Objekten in der Szene zuzuordnen. Dieser erlaubt uns, die Objekte und die Hintergrundszene mit Genauigkeit nach dem Stand der Technik und Robustheit gegen\u00fcber Verdeckungen zu verfolgen und zu rekonstruieren. Wir erforschen zwei Ans\u00e4tze, die rekonstruierte Form von bewegten Objekten basierend auf physikalischer Plausibilit\u00e4t weiter zu optimieren. Der erste hiervon, \"Co-Section\", schlie\u00dft physikalische Plausibilit\u00e4t durch Argumentationen \u00fcber den leeren Raum um ein Objekt herum ein. Wir stellen fest, dass keine zwei Objekte denselben Raum zur selben Zeit einnehmen k\u00f6nnen und dass die Tiefenbilder im Eingabevideo eine Sch\u00e4tzung von beobachtetem leeren Raum liefern. Basierend auf diesen Feststellungen schlagen wir H\u00fcllen- und \u00dcberschneidungsbeschr\u00e4nkungen vor, welche wir mit den beobachteten Oberfl\u00e4chen in einem globalen Optimierungsansatz kombinieren. Verglichen mit EM-Fusion, welches nur die beobachteten Oberfl\u00e4chen rekonstruiert, optimiert Co-Section wasserdichte Objektformen. Diese wasserdichten Formen liefern eine grobe Sch\u00e4tzung \u00fcber Oberfl\u00e4chen, die nicht direkt gesehen wurden, und k\u00f6nnen als Initialisierung f\u00fcr weitere Verbesserung, z.B. durch interaktive Wahrnehmung, dienen. Im zweiten Optimierungsansatz, \"DiffSDFSim\", argumentieren wir \u00fcber Objektformen basierend auf physikalisch plausibler Objektbewegung. Wir stellen fest, dass Objekttrajektorien nach Kollisionen von der Objektform abh\u00e4ngen, und erweitern eine differenzierbare Physiksimulation, um die Objektformen gemeinsam mit anderen physikalischen Eigenschaften (z.B. Kr\u00e4fte, Massen, Reibung) basierend auf der Bewegung der Objekte und ihrer Interaktionen zu optimieren. Unsere Hauptbeitr\u00e4ge sind die Verwendung vorzeichenbehafteter Distanzfunktionen zur Repr\u00e4sentation von Objektformen, und eine neue Methode zur Berechnung von Gradienten, welche die Abh\u00e4ngigkeit des Kontaktzeitpunkts von der Objektform modelliert. Wir zeigen, dass unser Ansatz Referenzformen durch das Anpassen auf Referenztrajektorien und Tiefenmessungen gut rekonstruiert. Weiterhin werden die wahren Trajektorien in der Simulation mit den optimierten Formen und physikalischen Eigenschaften gut rekonstruiert, was Vorhersagen \u00fcber zuk\u00fcnftige Bewegungen der Objekte durch die Physiksimulation zul\u00e4sst. Wir gehen davon aus, dass unsere Beitr\u00e4ge n\u00fctzliche Bausteine in der Entwicklung von 3D Umgebungswahrnehmung f\u00fcr Roboter sein k\u00f6nnen. Die Rekonstruktion einzelner Objekte, wie in EM-Fusion, ist ein Schl\u00fcsselbaustein, welche f\u00fcr die Interaktion mit Objekten ben\u00f6tigt wird. Vervollst\u00e4ndigte Formen, wie sie Co-Section bereitstellt, liefern n\u00fctzliche Hinweise, um Interaktionen wie das Greifen von Objekten zu planen. Schlie\u00dflich erlaubt die Sch\u00e4tzung von Form- und anderen physikalischen Parametern mittels differenzierbarer Physiksimulation, wie in DiffSDFSim, Objekte zu simulieren und damit die Effekte von Interaktionen vorherzusagen. Zuk\u00fcnftige Arbeiten k\u00f6nnten die pr\u00e4sentierten Ans\u00e4tze zur interaktiven Wahrnehmung dynamischer Umgebungen erweitern, indem diese Vorhersagen mit beobachteten Interaktionen in der echten Welt verglichen werden, um die Rekonstruktionen und physikalischen Parametersch\u00e4tzungen weiter zu verbessern."
            ],
            "contributor": "Technische Informationsbibliothek (TIB)",
            "creator": [
                "gnd:1325178489",
                "gnd:36187-2"
            ],
            "isPartOf": "(collectioncode)GBV-ODiss",
            "issued": "2023",
            "language": "http://id.loc.gov/vocabulary/iso639-1/en",
            "license": "open access",
            "medium": "rda:termList/RDACarrierType/1018",
            "isLike": "doi:10.15496/publikation-93808",
            "P60163": "T\u00fcbingen"
        }
    ],
    "@id": "urn:x-arq:DefaultGraphNode",
    "@context": {
        "subject": "http://purl.org/dc/elements/1.1/subject",
        "abstract": "http://purl.org/dc/terms/abstract",
        "title": "http://purl.org/dc/elements/1.1/title",
        "isPartOf": "http://purl.org/dc/terms/isPartOf",
        "isLike": {
            "@id": "http://umbel.org/umbel#isLike",
            "@type": "@id"
        },
        "description": "http://purl.org/dc/elements/1.1/description",
        "identifier": "http://purl.org/dc/elements/1.1/identifier",
        "medium": {
            "@id": "http://purl.org/dc/terms/medium",
            "@type": "@id"
        },
        "P60163": "http://www.rdaregistry.info/Elements/u/#P60163",
        "language": {
            "@id": "http://purl.org/dc/terms/language",
            "@type": "@id"
        },
        "contributor": "http://purl.org/dc/terms/contributor",
        "creator": {
            "@id": "http://purl.org/dc/terms/creator",
            "@type": "@id"
        },
        "issued": "http://purl.org/dc/terms/issued",
        "P1053": "http://iflastandards.info/ns/isbd/elements/P1053",
        "license": "http://purl.org/dc/terms/license",
        "sameAs": "http://www.w3.org/2002/07/owl#sameAs",
        "umbel": "http://umbel.org/umbel#",
        "rdau": "http://www.rdaregistry.info/Elements/u/#",
        "owl": "http://www.w3.org/2002/07/owl#",
        "dcterms": "http://purl.org/dc/terms/",
        "bibo": "http://purl.org/ontology/bibo/",
        "rdam": "http://www.rdaregistry.info/Elements/m/#",
        "gnd": "http://d-nb.info/gnd/",
        "isbd": "http://iflastandards.info/ns/isbd/elements/",
        "rda": "http://rdvocab.info/",
        "doi": "https://doi.org/"
    }
}