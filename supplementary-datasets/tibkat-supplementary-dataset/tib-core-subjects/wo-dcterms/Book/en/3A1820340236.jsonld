{
    "@graph": [
        {
            "@id": "https://www.tib.eu/de/suchen/id/TIBKAT%3A1820340236",
            "@type": "bibo:Book",
            "P1053": "1 Online-Ressource(XIV, 184 p. 74 illus., 63 illus. in color.)",
            "creator": "Lorenz, Uwe",
            "description": [
                "Erworben aus Studienqualit\u00e4tsmitteln",
                "Campusweiter Zugriff (Universit\u00e4t Hannover) - Vervielf\u00e4ltigungen (z.B. Kopien, Downloads) sind nur von einzelnen Kapiteln oder Seiten und nur zum eigenen wissenschaftlichen Gebrauch erlaubt. Keine Weitergabe an Dritte. Kein systematisches Downloaden durch Robots."
            ],
            "identifier": [
                "(doi)10.1007/978-3-031-09030-1",
                "(ppn)1820340236",
                "(isbn13)9783031090301",
                "(firstid)KEP:082396558"
            ],
            "publisher": "Springer International Publishing",
            "subject": [
                "(classificationName=ddc)006.31",
                "Data mining.",
                "(classificationName=linseach:mapping)inf",
                "Machine learning.",
                "Java (Computer program language)."
            ],
            "title": "Reinforcement Learning From Scratch : Understanding Current Approaches - with Examples in Java and Greenfoot",
            "abstract": [
                "1 Reinforcement learning as subfield of machine learning -- 2 Basic concepts of reinforcement learning -- 3 Optimal decision-making in a known environment -- 4 decision making and learning in an unknown environment -- 5 Artificial Neural Networks as estimators for state values and the action selection -- 6 Guiding ideas in Artificial Intelligence over time.",
                "In ancient games such as chess or go, the most brilliant players can improve by studying the strategies produced by a machine. Robotic systems practice their own movements. In arcade games, agents capable of learning reach superhuman levels within a few hours. How do these spectacular reinforcement learning algorithms work? With easy-to-understand explanations and clear examples in Java and Greenfoot, you can acquire the principles of reinforcement learning and apply them in your own intelligent agents. Greenfoot (M.K\u00f6lling, King's College London) and the hamster model (D. Bohles, University of Oldenburg) are simple but also powerful didactic tools that were developed to convey basic programming concepts. The result is an accessible introduction into machine learning that concentrates on reinforcement learning. Taking the reader through the steps of developing intelligent agents, from the very basics to advanced aspects, touching on a variety of machine learning algorithms along the way, one is allowed to play along, experiment, and add their own ideas and experiments. This book is a translation of an original German edition. The translation was done with the help of artificial intelligence (machine translation by the service DeepL.com). A subsequent human revision was done primarily in terms of content, so that the book will read stylistically differently from a conventional translation."
            ],
            "contributor": "Technische Informationsbibliothek (TIB)",
            "isPartOf": [
                "(collectioncode)ZDB-2-SEB",
                "(collectioncode)ZDB-2-SXMS",
                "(collectioncode)ZDB-2-SMA"
            ],
            "issued": "2022",
            "language": "http://id.loc.gov/vocabulary/iso639-1/en",
            "license": "commercial licence",
            "medium": "rda:termList/RDACarrierType/1018",
            "isLike": "doi:10.1007/978-3-031-09030-1",
            "P60163": "Cham"
        }
    ],
    "@id": "urn:x-arq:DefaultGraphNode",
    "@context": {
        "P60163": "http://www.rdaregistry.info/Elements/u/#P60163",
        "medium": {
            "@id": "http://purl.org/dc/terms/medium",
            "@type": "@id"
        },
        "abstract": "http://purl.org/dc/terms/abstract",
        "contributor": "http://purl.org/dc/terms/contributor",
        "issued": "http://purl.org/dc/terms/issued",
        "subject": "http://purl.org/dc/elements/1.1/subject",
        "description": "http://purl.org/dc/elements/1.1/description",
        "identifier": "http://purl.org/dc/elements/1.1/identifier",
        "language": {
            "@id": "http://purl.org/dc/terms/language",
            "@type": "@id"
        },
        "isPartOf": "http://purl.org/dc/terms/isPartOf",
        "publisher": "http://purl.org/dc/elements/1.1/publisher",
        "isLike": {
            "@id": "http://umbel.org/umbel#isLike",
            "@type": "@id"
        },
        "creator": "http://purl.org/dc/elements/1.1/creator",
        "title": "http://purl.org/dc/elements/1.1/title",
        "P1053": "http://iflastandards.info/ns/isbd/elements/P1053",
        "license": "http://purl.org/dc/terms/license",
        "umbel": "http://umbel.org/umbel#",
        "rdau": "http://www.rdaregistry.info/Elements/u/#",
        "owl": "http://www.w3.org/2002/07/owl#",
        "dcterms": "http://purl.org/dc/terms/",
        "bibo": "http://purl.org/ontology/bibo/",
        "rdam": "http://www.rdaregistry.info/Elements/m/#",
        "gnd": "http://d-nb.info/gnd/",
        "isbd": "http://iflastandards.info/ns/isbd/elements/",
        "rda": "http://rdvocab.info/",
        "doi": "https://doi.org/"
    }
}