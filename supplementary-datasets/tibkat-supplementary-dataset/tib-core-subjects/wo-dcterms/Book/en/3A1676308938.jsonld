{
    "@graph": [
        {
            "@id": "https://www.tib.eu/de/suchen/id/TIBKAT%3A1676308938",
            "@type": "bibo:Book",
            "P1053": "1 Online-Ressource (XV, 168 Seiten)",
            "creator": "Beysolow II, Taweh",
            "description": [
                "Campusweiter Zugriff (Universit\u00e4t Hannover) - Vervielf\u00e4ltigungen (z.B. Kopien, Downloads) sind nur von einzelnen Kapiteln oder Seiten und nur zum eigenen wissenschaftlichen Gebrauch erlaubt. Keine Weitergabe an Dritte. Kein systematisches Downloaden durch Robots.",
                "Illustrationen, Diagramme",
                "Erworben aus Studienqualit\u00e4tsmitteln"
            ],
            "identifier": [
                "(ppn)1676308938",
                "(doi)10.1007/978-1-4842-5127-0",
                "(isbn13)9781484251270",
                "(firstid)KEP:046511466"
            ],
            "publisher": "Apress",
            "subject": [
                "Open source software",
                "Python (Computer program language)",
                "(classificationName=linseach:mapping)rest",
                "Artificial Intelligence",
                "Artificial intelligence",
                "(classificationName=ddc)006.3",
                "Computer programming",
                "(classificationName=loc)Q334-342"
            ],
            "title": "Applied reinforcement learning with Python : with OpenAI Gym, Tensorflow, and Keras",
            "abstract": [
                "Chapter 1: Introduction to Reinforcement Learning -- Chapter 2: Reinforcement Learning Algorithms -- Chapter 3: Q Learning -- Chapter 4: Reinforcement Learning Based Market Making -- Chapter 5: Reinforcement Learning for Video Games",
                "Delve into the world of reinforcement learning algorithms and apply them to different use-cases via Python. This book covers important topics such as policy gradients and Q learning, and utilizes frameworks such as Tensorflow, Keras, and OpenAI Gym. Applied Reinforcement Learning with Python introduces you to the theory behind reinforcement learning (RL) algorithms and the code that will be used to implement them. You will take a guided tour through features of OpenAI Gym, from utilizing standard libraries to creating your own environments, then discover how to frame reinforcement learning problems so you can research, develop, and deploy RL-based solutions. What You'll Learn: Implement reinforcement learning with Python Work with AI frameworks such as OpenAI Gym, Tensorflow, and Keras Deploy and train reinforcement learning\u2013based solutions via cloud resources Apply practical applications of reinforcement learning"
            ],
            "contributor": "Technische Informationsbibliothek (TIB)",
            "isPartOf": [
                "(collectioncode)ZDB-2-SXPC",
                "(collectioncode)ZDB-2-SEB",
                "(collectioncode)ZDB-2-CWD"
            ],
            "issued": "2019",
            "language": "http://id.loc.gov/vocabulary/iso639-1/en",
            "license": "commercial licence",
            "medium": "rda:termList/RDACarrierType/1018",
            "isLike": "doi:10.1007/978-1-4842-5127-0",
            "P30128": [
                "Professional and Applied Computing",
                "Springer eBooks",
                "Springer eBook Collection"
            ],
            "P60163": "New York"
        }
    ],
    "@id": "urn:x-arq:DefaultGraphNode",
    "@context": {
        "language": {
            "@id": "http://purl.org/dc/terms/language",
            "@type": "@id"
        },
        "description": "http://purl.org/dc/elements/1.1/description",
        "P30128": "http://www.rdaregistry.info/Elements/m/#P30128",
        "contributor": "http://purl.org/dc/terms/contributor",
        "license": "http://purl.org/dc/terms/license",
        "issued": "http://purl.org/dc/terms/issued",
        "subject": "http://purl.org/dc/elements/1.1/subject",
        "P60163": "http://www.rdaregistry.info/Elements/u/#P60163",
        "identifier": "http://purl.org/dc/elements/1.1/identifier",
        "abstract": "http://purl.org/dc/terms/abstract",
        "isPartOf": "http://purl.org/dc/terms/isPartOf",
        "creator": "http://purl.org/dc/elements/1.1/creator",
        "medium": {
            "@id": "http://purl.org/dc/terms/medium",
            "@type": "@id"
        },
        "title": "http://purl.org/dc/elements/1.1/title",
        "isLike": {
            "@id": "http://umbel.org/umbel#isLike",
            "@type": "@id"
        },
        "publisher": "http://purl.org/dc/elements/1.1/publisher",
        "P1053": "http://iflastandards.info/ns/isbd/elements/P1053",
        "umbel": "http://umbel.org/umbel#",
        "rdau": "http://www.rdaregistry.info/Elements/u/#",
        "owl": "http://www.w3.org/2002/07/owl#",
        "dcterms": "http://purl.org/dc/terms/",
        "bibo": "http://purl.org/ontology/bibo/",
        "rdam": "http://www.rdaregistry.info/Elements/m/#",
        "gnd": "http://d-nb.info/gnd/",
        "isbd": "http://iflastandards.info/ns/isbd/elements/",
        "rda": "http://rdvocab.info/",
        "doi": "https://doi.org/"
    }
}