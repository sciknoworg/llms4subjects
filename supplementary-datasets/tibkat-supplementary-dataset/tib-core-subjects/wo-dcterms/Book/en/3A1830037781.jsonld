{
    "@graph": [
        {
            "@id": "https://www.tib.eu/de/suchen/id/TIBKAT%3A1830037781",
            "@type": "bibo:Book",
            "P1053": "1 Online-Ressource(XV, 423 p. 85 illus., 84 illus. in color.)",
            "creator": "Ahlawat, Samit",
            "description": "Campusweiter Zugriff (Universit\u00e4t Hannover) - Vervielf\u00e4ltigungen (z.B. Kopien, Downloads) sind nur von einzelnen Kapiteln oder Seiten und nur zum eigenen wissenschaftlichen Gebrauch erlaubt. Keine Weitergabe an Dritte. Kein systematisches Downloaden durch Robots.",
            "identifier": [
                "(ppn)1830037781",
                "(firstid)KEP:083428100",
                "(doi)10.1007/978-1-4842-8835-1",
                "(isbn13)9781484288351"
            ],
            "publisher": "Apress",
            "subject": [
                "Machine learning.",
                "(classificationName=linseach:mapping)inf",
                "Python (Computer program language).",
                "(classificationName=ddc)006.31",
                "Artificial intelligence."
            ],
            "title": "Reinforcement Learning for Finance : Solve Problems in Finance with CNN and RNN Using the TensorFlow Library",
            "abstract": [
                "This book introduces reinforcement learning with mathematical theory and practical examples from quantitative finance using the TensorFlow library. Reinforcement Learning for Finance begins by describing methods for training neural networks. Next, it discusses CNN and RNN \u2013 two kinds of neural networks used as deep learning networks in reinforcement learning. Further, the book dives into reinforcement learning theory, explaining the Markov decision process, value function, policy, and policy gradients, with their mathematical formulations and learning algorithms. It covers recent reinforcement learning algorithms from double deep-Q networks to twin-delayed deep deterministic policy gradients and generative adversarial networks with examples using the TensorFlow Python library. It also serves as a quick hands-on guide to TensorFlow programming, covering concepts ranging from variables and graphs to automatic differentiation, layers, models, and loss functions. After completing this book, you will understand reinforcement learning with deep q and generative adversarial networks using the TensorFlow library. What You Will Learn Understand the fundamentals of reinforcement learning Apply reinforcement learning programming techniques to solve quantitative-finance problems Gain insight into convolutional neural networks and recurrent neural networks Understand the Markov decision process Who This Book Is For Data Scientists, Machine Learning engineers and Python programmers who want to apply reinforcement learning to solve problems.",
                "Chapter 1 Overview -- Chapter 2 Introduction to TensorFlow -- Chapter 3 Convolutional Neural Networks -- Chapter 4 Recurrent Neural Networks -- Chapter 5 Reinforcement Learning - Theory -- Chapter 6 Recent RL Algorithms."
            ],
            "contributor": "Technische Informationsbibliothek (TIB)",
            "isPartOf": [
                "(collectioncode)ZDB-2-SEB",
                "(collectioncode)ZDB-2-CWD",
                "(collectioncode)ZDB-2-SXPC"
            ],
            "issued": "2023",
            "language": "http://id.loc.gov/vocabulary/iso639-1/en",
            "license": "commercial licence",
            "medium": "rda:termList/RDACarrierType/1018",
            "isLike": "doi:10.1007/978-1-4842-8835-1",
            "P60163": "Berkeley, CA"
        }
    ],
    "@id": "urn:x-arq:DefaultGraphNode",
    "@context": {
        "isPartOf": "http://purl.org/dc/terms/isPartOf",
        "license": "http://purl.org/dc/terms/license",
        "abstract": "http://purl.org/dc/terms/abstract",
        "subject": "http://purl.org/dc/elements/1.1/subject",
        "description": "http://purl.org/dc/elements/1.1/description",
        "P60163": "http://www.rdaregistry.info/Elements/u/#P60163",
        "issued": "http://purl.org/dc/terms/issued",
        "creator": "http://purl.org/dc/elements/1.1/creator",
        "isLike": {
            "@id": "http://umbel.org/umbel#isLike",
            "@type": "@id"
        },
        "identifier": "http://purl.org/dc/elements/1.1/identifier",
        "publisher": "http://purl.org/dc/elements/1.1/publisher",
        "language": {
            "@id": "http://purl.org/dc/terms/language",
            "@type": "@id"
        },
        "contributor": "http://purl.org/dc/terms/contributor",
        "P1053": "http://iflastandards.info/ns/isbd/elements/P1053",
        "title": "http://purl.org/dc/elements/1.1/title",
        "medium": {
            "@id": "http://purl.org/dc/terms/medium",
            "@type": "@id"
        },
        "umbel": "http://umbel.org/umbel#",
        "rdau": "http://www.rdaregistry.info/Elements/u/#",
        "owl": "http://www.w3.org/2002/07/owl#",
        "dcterms": "http://purl.org/dc/terms/",
        "bibo": "http://purl.org/ontology/bibo/",
        "rdam": "http://www.rdaregistry.info/Elements/m/#",
        "gnd": "http://d-nb.info/gnd/",
        "isbd": "http://iflastandards.info/ns/isbd/elements/",
        "rda": "http://rdvocab.info/",
        "doi": "https://doi.org/"
    }
}