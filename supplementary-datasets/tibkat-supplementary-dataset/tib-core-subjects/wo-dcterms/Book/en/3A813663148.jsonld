{
    "@graph": [
        {
            "@id": "https://www.tib.eu/de/suchen/id/TIBKAT%3A813663148",
            "@type": "bibo:Book",
            "P1053": "Online-Ressource (XVI, 392 p. 168 illus)",
            "creator": "Frampton, Michael",
            "description": [
                "Campusweiter Zugriff (Universit\u00e4t Hannover). - Vervielf\u00e4ltigungen (z.B. Kopien, Downloads) sind nur von einzelnen Kapiteln oder Seiten und nur zum eigenen wissenschaftlichen Gebrauch erlaubt. Keine Weitergabe an Dritte. Kein systematisches Downloaden durch Robots.",
                "online resource"
            ],
            "identifier": [
                "(ppn)813663148",
                "(firstid)GBV:813663148",
                "(doi)10.1007/978-1-4842-0094-0",
                "(isbn13)9781484200940"
            ],
            "publisher": "Apress",
            "subject": [
                "(classificationName=rvk)ST 270",
                "(classificationName=loc)QA76.9.D3",
                "Database management",
                "(classificationName=linseach:mapping)inf",
                "Information systems",
                "(classificationName=ddc)005.74",
                "Computer science"
            ],
            "title": "Big data made easy : a working guide to the complete Hadoop toolset",
            "abstract": "Many corporations are finding that the size of their data sets are outgrowing the capability of their systems to store and process them. The data is becoming too big to manage and use with traditional tools. The solution: implementing a big data system. As Big Data Made Easy: A Working Guide to the Complete Hadoop Toolset shows, Apache Hadoop offers a scalable, fault-tolerant system for storing and processing data in parallel. It has a very rich toolset that allows for storage (Hadoop), configuration (YARN and ZooKeeper), collection (Nutch and Solr), processing (Storm, Pig, and Map Reduce), scheduling (Oozie), moving (Sqoop and Avro), monitoring (Chukwa, Ambari, and Hue), testing (Big Top), and analysis (Hive). The problem is that the Internet offers IT pros wading into big data many versions of the truth and some outright falsehoods born of ignorance. What is needed is a book just like this one: a wide-ranging but easily understood set of instructions to explain where to get Hadoop tools, what they can do, how to install them, how to configure them, how to integrate them, and how to use them successfully. And you need an expert who has worked in this area for a decade-someone just like author and big data expert Mike Frampton. Big Data Made Easy approaches the problem of managing massive data sets from a systems perspective, and it explains the roles for each project (like architect and tester, for example) and shows how the Hadoop toolset can be used at each system stage. It explains, in an easily understood manner and through numerous examples, how to use each tool. The book also explains the sliding scale of tools available depending upon data size and when and how to use them. Big Data Made Easy shows developers and architects, as well as testers and project managers, how to: Store big data Configure big data Process big data Schedule processes Move data among SQL and NoSQL systems Monitor data Perform big data analytics Report on big data processes and projects Test big data systems Big Data Made Easy also explains the best part, which is that this toolset is free. Anyone can download it and-with the help of this book-start to use it within a day. With the skills this book will teach you under your belt, you will add value to your company or client immediately, not to mention your career",
            "contributor": "Technische Informationsbibliothek (TIB)",
            "isPartOf": "(collectioncode)H-ZDB-2-CWD",
            "issued": "2015",
            "language": "http://id.loc.gov/vocabulary/iso639-1/en",
            "license": "commercial licence",
            "medium": "rda:termList/RDACarrierType/1018",
            "isLike": "doi:10.1007/978-1-4842-0094-0",
            "P30128": "The expert's voice in big data",
            "P60163": "[Berkeley, Calif.]"
        }
    ],
    "@id": "urn:x-arq:DefaultGraphNode",
    "@context": {
        "identifier": "http://purl.org/dc/elements/1.1/identifier",
        "publisher": "http://purl.org/dc/elements/1.1/publisher",
        "creator": "http://purl.org/dc/elements/1.1/creator",
        "subject": "http://purl.org/dc/elements/1.1/subject",
        "P30128": "http://www.rdaregistry.info/Elements/m/#P30128",
        "description": "http://purl.org/dc/elements/1.1/description",
        "license": "http://purl.org/dc/terms/license",
        "isPartOf": "http://purl.org/dc/terms/isPartOf",
        "title": "http://purl.org/dc/elements/1.1/title",
        "P60163": "http://www.rdaregistry.info/Elements/u/#P60163",
        "language": {
            "@id": "http://purl.org/dc/terms/language",
            "@type": "@id"
        },
        "P1053": "http://iflastandards.info/ns/isbd/elements/P1053",
        "isLike": {
            "@id": "http://umbel.org/umbel#isLike",
            "@type": "@id"
        },
        "issued": "http://purl.org/dc/terms/issued",
        "medium": {
            "@id": "http://purl.org/dc/terms/medium",
            "@type": "@id"
        },
        "contributor": "http://purl.org/dc/terms/contributor",
        "abstract": "http://purl.org/dc/terms/abstract",
        "umbel": "http://umbel.org/umbel#",
        "rdau": "http://www.rdaregistry.info/Elements/u/#",
        "owl": "http://www.w3.org/2002/07/owl#",
        "dcterms": "http://purl.org/dc/terms/",
        "bibo": "http://purl.org/ontology/bibo/",
        "rdam": "http://www.rdaregistry.info/Elements/m/#",
        "gnd": "http://d-nb.info/gnd/",
        "isbd": "http://iflastandards.info/ns/isbd/elements/",
        "rda": "http://rdvocab.info/",
        "doi": "https://doi.org/"
    }
}