{
    "@graph": [
        {
            "@id": "gnd:115233865X",
            "sameAs": "Sevgi, Meltem"
        },
        {
            "@id": "gnd:128567961",
            "sameAs": "Donner, Tobias H."
        },
        {
            "@id": "gnd:143795244",
            "sameAs": "Haueisen, Jens"
        },
        {
            "@id": "gnd:2125187-3",
            "sameAs": "Technische Universit\u00e4t Ilmenau"
        },
        {
            "@id": "gnd:4047686-8",
            "sameAs": "Psychische St\u00f6rung"
        },
        {
            "@id": "gnd:4120666-6",
            "sameAs": "Lernendes System"
        },
        {
            "@id": "gnd:4121849-8",
            "sameAs": "Verhaltensmuster"
        },
        {
            "@id": "gnd:4144220-9",
            "sameAs": "Bayes-Entscheidungstheorie"
        },
        {
            "@id": "gnd:4172613-3",
            "sameAs": "Operante Konditionierung"
        },
        {
            "@id": "gnd:4366912-8",
            "sameAs": "Evolution\u00e4rer Algorithmus"
        },
        {
            "@id": "gnd:7618675-1",
            "sameAs": "Funktionelle Kernspintomografie"
        },
        {
            "@id": "https://www.tib.eu/de/suchen/id/TIBKAT%3A1013873637",
            "@type": "bibo:Thesis",
            "P1053": "1 Online-Ressource (xvi, 114 Seiten)",
            "http://purl.org/dc/elements/1.1/contributor": "Moran, Rosalyn",
            "description": "Diagramme, Illustrationen (teilweise farbig)",
            "identifier": [
                "(firstid)GBV:1013873637",
                "(ppn)1013873637"
            ],
            "publisher": "Universit\u00e4tsbibliothek",
            "http://purl.org/dc/elements/1.1/subject": [
                "(classificationName=linseach:mapping)inf",
                "(classificationName=ddc-dbn)004",
                "(classificationName=ddc)006.31"
            ],
            "title": "Mechanistic models of reward based learning and decision making for clinically motivated problems",
            "abstract": "Mechanistische Modelle f\u00fcr Lernen und zur Entscheidungsfindung k\u00f6nnen helfen, spezifische Hypothesen \u00fcber beobachtetes Verhalten und dessen Etablierung in Gehirn zu testen. Die hier vorliegende Arbeit bietet einen Ansatz, um computergest\u00fctzte Modelle zum Verst\u00e4rkungslernen (Reinforcement Learning) und Bayes'sche Lernalgorithmen zu integrieren, und um klinisch motivierte Probleme zu adressieren. Die so entstandenen Modelle wurden anhand von funktionelle Magnetresonanztomographie (fMRT) gemeinsam mit Verhaltens- und Konnektivit\u00e4tsmodellen evaluiert. In dieser Arbeit werden vor allem Algorithmen zum Verst\u00e4rkungslernen betrachtet, typischerweise die im bildgebenden und in psychologischen Studien zur Anwendung kommen. Eine Bewertung der Algorithmen erfolgte mithilfe von Simulationen, um somit das Verhalten von virtuellen Agenten bei unterschiedlichen Modellparametern und Strategien zu verstehen. Sp\u00e4ter wurden die generierten Modelle an einem empirischen Datensatz getestet, wobei das beste Modell zur Auswertung der fMRI Daten an ein lineares Modell \u00fcbergeben wurde. Solche Modelle konnten Unterschiede in der Funktion von dopaminergen Gehirnregionen und dem damit assoziierten Verhalten zwischen Individuen mit unterschiedlicher genetische Disposition zeigen. Weiterhin wurde untersucht, ob die Einbeziehung von Lernalgorithmen in effektive Konnektivit\u00e4tsmodelle als komplement\u00e4re Grundlage f\u00fcr die weitere Erforschung von ver\u00e4nderten Netzwerkdynamiken im menschlichen Gehirn dienen k\u00f6nnte. Dazu wurden bilineare und nicht-lineare dynamisch kausale Modelle verschiedener Hirnregionen, welche in Belohnungslernen und Vorhersagefehlerprozessen beteiligt sind, erstellt. In einer Erweiterung, wurden hierarchische Bayes'sche Modelle betrachtet, welche das Lernverhalten eines virtuellen Agenten in einer komplexen und unbest\u00e4ndigen Umgebung modellieren. Ein paralleler Lernansatz wurde zum Lernen und Kombinieren multipler Hinweisreize entwickelt, indem hierarchische Gauss'schen Filter mit pr\u00e4zisionsgewichteten Antwortmodellen gepaart wurden. Simulationen von Parametersch\u00e4tzungen deuten darauf hin, dass dieser Ansatz zum Lernen und Kombinieren verschiedener Informationsquellen genutzt werden kann. Das vorgeschlagene Modell wurde auf Grundlage empirische Daten \u00fcberpr\u00fcft und mit alternativen Modellen verglichen, wie beispielsweise mit dem optimalen Bayes'schen Agenten. Letztlich hat uns diese Methode erm\u00f6glicht, individuelle Subprozesse zu identifizieren, die am Lernen von sozialen Hinweisreizen beteiligt sind und die mit unterschiedlichen Auspr\u00e4gungen vom autistischen Z\u00fcge variieren. Dar\u00fcber hinaus postulieren wir, dass der hier vorgestellte experimentelle und modellierende Ansatz zu einer mechanistischen Beschreibung von unterschiedlichen psychiatrischen St\u00f6rungen beitragen kann.",
            "contributor": [
                "gnd:143795244",
                "gnd:128567961"
            ],
            "dcterms:contributor": "Technische Informationsbibliothek (TIB)",
            "creator": [
                "gnd:2125187-3",
                "gnd:115233865X"
            ],
            "isPartOf": "(collectioncode)GBV-ODiss",
            "issued": "2017",
            "language": "http://id.loc.gov/vocabulary/iso639-1/en",
            "license": "open access",
            "medium": "rda:termList/RDACarrierType/1018",
            "subject": [
                "gnd:4120666-6",
                "gnd:4047686-8",
                "gnd:4172613-3",
                "gnd:7618675-1",
                "gnd:4144220-9",
                "gnd:4366912-8",
                "gnd:4121849-8"
            ],
            "P60163": "Ilmenau"
        }
    ],
    "@id": "urn:x-arq:DefaultGraphNode",
    "@context": {
        "subject": {
            "@id": "http://purl.org/dc/terms/subject",
            "@type": "@id"
        },
        "P60163": "http://www.rdaregistry.info/Elements/u/#P60163",
        "contributor": {
            "@id": "http://purl.org/dc/terms/contributor",
            "@type": "@id"
        },
        "publisher": "http://purl.org/dc/elements/1.1/publisher",
        "language": {
            "@id": "http://purl.org/dc/terms/language",
            "@type": "@id"
        },
        "license": "http://purl.org/dc/terms/license",
        "identifier": "http://purl.org/dc/elements/1.1/identifier",
        "description": "http://purl.org/dc/elements/1.1/description",
        "medium": {
            "@id": "http://purl.org/dc/terms/medium",
            "@type": "@id"
        },
        "title": "http://purl.org/dc/elements/1.1/title",
        "abstract": "http://purl.org/dc/terms/abstract",
        "P1053": "http://iflastandards.info/ns/isbd/elements/P1053",
        "creator": {
            "@id": "http://purl.org/dc/terms/creator",
            "@type": "@id"
        },
        "isPartOf": "http://purl.org/dc/terms/isPartOf",
        "issued": "http://purl.org/dc/terms/issued",
        "sameAs": "http://www.w3.org/2002/07/owl#sameAs",
        "umbel": "http://umbel.org/umbel#",
        "rdau": "http://www.rdaregistry.info/Elements/u/#",
        "owl": "http://www.w3.org/2002/07/owl#",
        "dcterms": "http://purl.org/dc/terms/",
        "bibo": "http://purl.org/ontology/bibo/",
        "rdam": "http://www.rdaregistry.info/Elements/m/#",
        "gnd": "http://d-nb.info/gnd/",
        "isbd": "http://iflastandards.info/ns/isbd/elements/",
        "rda": "http://rdvocab.info/",
        "doi": "https://doi.org/"
    }
}