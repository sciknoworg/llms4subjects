{
    "@graph": [
        {
            "@id": "gnd:1092325816",
            "sameAs": "Ruckdeschel, Peter"
        },
        {
            "@id": "gnd:1203400942",
            "sameAs": "Werner, Tino"
        },
        {
            "@id": "gnd:4121498-5",
            "sameAs": "Pr\u00e4diktor"
        },
        {
            "@id": "gnd:4126634-1",
            "sameAs": "Asymptotik"
        },
        {
            "@id": "gnd:4307945-3",
            "sameAs": "Ranking"
        },
        {
            "@id": "gnd:4323954-7",
            "sameAs": "Gradient"
        },
        {
            "@id": "gnd:4839853-6",
            "sameAs": "Boosting"
        },
        {
            "@id": "https://www.tib.eu/de/suchen/id/TIBKAT%3A1691628751",
            "@type": "bibo:Thesis",
            "P1053": "1 Online-Ressource (xxviii, 390 Seiten, 2,7 MB)",
            "http://purl.org/dc/elements/1.1/contributor": "Schmid, Matthias",
            "identifier": [
                "(firstid)DNB:120419968X",
                "(ppn)1691628751"
            ],
            "http://purl.org/dc/elements/1.1/subject": [
                "(classificationName=ddc)519.53",
                "(classificationName=ddc-dbn)510",
                "(classificationName=linseach:mapping)mat"
            ],
            "title": "Gradient-Free Gradient Boosting",
            "abstract": [
                "Motiviert durch Anwendungen in der Betrugsdetektion besch\u00e4ftigt sich die Dissertation mit der Modellwahl in pr\u00e4diktiven Modellen, in denen das korrekte Ranking von Beobachtungen vorhergesagt werden soll. Hierzu beweist die Arbeit zun\u00e4chst die asymptotische Linearit\u00e4t einer ganzen Familie regularisierter M-Sch\u00e4tzer, die u.A. das Lasso abdeckt. Mit dem in der Dissertation entwickelten Verfahren ,,SingBoost'' gelingt es, trotz unstetiger Verlustfunktion auch im Rankingproblem ein Gradienten-Boosting in Erweiterung des L2-Boostings bereitzustellen. Wir beweisen: Dieser Algorithmus besitzt entsprechende Konsistenz-Eigenschaften wie das L2-Boosting. F\u00fcr eine stabile Modellwahl wird eine verlustbasierte Stabilit\u00e4tsselektion entwickelt. Auf simulierten Daten verbessert SingBoost verbunden mit dieser Stabilit\u00e4tsselektion die Performance f\u00fcr das harte stetige Rankingproblem strikt. Die hierzu entwickelte Stabilit\u00e4tsselektion ist dabei universell, f\u00fcr beliebige Verlustfunktionen, einsetzbar.",
                "Motivated by applications in fraud detection, this dissertation is concerned about model selection in predictive models where the correct ranking of observations has to be predicted. For this, the thesis starts by proving the asymptotic linearity of a whole family of regularized M-estimators which covers for example the Lasso. With the algorithm ''SingBoost'' developed in this dissertation, we succeed in providing a Gradient Boosting algorithm as an extension of L2-Boosting, even though the loss function is non-continuous. We prove: This algorithm has analogous consistency properties as L2-Boosting. As to stable model selection, we develop a loss-based Stability Selection. In combination with this Stability Selection, SingBoost strictly improves the performance for the hard ranking problem on simulated data. The loss-based Stability Selection that we provide is universally applicable, i.e., for arbitrary loss functions."
            ],
            "alternative": "Gradientenfreies Gradienten-Boosting",
            "contributor": [
                "Technische Informationsbibliothek (TIB)",
                {
                    "@id": "gnd:1092325816"
                }
            ],
            "creator": "gnd:1203400942",
            "isPartOf": "(collectioncode)GBV-ODiss",
            "issued": "2020",
            "language": "http://id.loc.gov/vocabulary/iso639-1/de",
            "license": "open access",
            "medium": "rda:termList/RDACarrierType/1018",
            "subject": [
                "gnd:4307945-3",
                "gnd:4839853-6",
                "gnd:4126634-1",
                "gnd:4121498-5",
                "gnd:4323954-7"
            ],
            "P60163": "Oldenburg"
        }
    ],
    "@id": "urn:x-arq:DefaultGraphNode",
    "@context": {
        "sameAs": "http://www.w3.org/2002/07/owl#sameAs",
        "subject": {
            "@id": "http://purl.org/dc/terms/subject",
            "@type": "@id"
        },
        "isPartOf": "http://purl.org/dc/terms/isPartOf",
        "identifier": "http://purl.org/dc/elements/1.1/identifier",
        "language": {
            "@id": "http://purl.org/dc/terms/language",
            "@type": "@id"
        },
        "title": "http://purl.org/dc/elements/1.1/title",
        "contributor": "http://purl.org/dc/terms/contributor",
        "P60163": "http://www.rdaregistry.info/Elements/u/#P60163",
        "medium": {
            "@id": "http://purl.org/dc/terms/medium",
            "@type": "@id"
        },
        "P1053": "http://iflastandards.info/ns/isbd/elements/P1053",
        "abstract": "http://purl.org/dc/terms/abstract",
        "alternative": "http://purl.org/dc/terms/alternative",
        "creator": {
            "@id": "http://purl.org/dc/terms/creator",
            "@type": "@id"
        },
        "issued": "http://purl.org/dc/terms/issued",
        "license": "http://purl.org/dc/terms/license",
        "umbel": "http://umbel.org/umbel#",
        "rdau": "http://www.rdaregistry.info/Elements/u/#",
        "owl": "http://www.w3.org/2002/07/owl#",
        "dcterms": "http://purl.org/dc/terms/",
        "bibo": "http://purl.org/ontology/bibo/",
        "rdam": "http://www.rdaregistry.info/Elements/m/#",
        "gnd": "http://d-nb.info/gnd/",
        "isbd": "http://iflastandards.info/ns/isbd/elements/",
        "rda": "http://rdvocab.info/",
        "doi": "https://doi.org/"
    }
}