{
    "@graph": [
        {
            "@id": "gnd:1278060960",
            "sameAs": "Blaes, Sebastian"
        },
        {
            "@id": "gnd:36187-2",
            "sameAs": "Eberhard Karls Universit\u00e4t T\u00fcbingen"
        },
        {
            "@id": "https://www.tib.eu/de/suchen/id/TIBKAT%3A1831049198",
            "@type": "bibo:Thesis",
            "P1053": "1 Online-Ressource (xxiv, 157 Seiten)",
            "description": "Illustrationen",
            "identifier": [
                "(firstid)KXP:1831049198",
                "(doi)10.15496/publikation-76028",
                "(ppn)1831049198"
            ],
            "subject": [
                "(classificationName=ddc-dbn)004",
                "Maschinelles Lernen",
                "Robotik",
                "(classificationName=ddc-dbn)006.31",
                "(classificationName=linseach:mapping)inf",
                "Operante Konditionierung"
            ],
            "title": "Nature-inspired inductive biases in learning robots",
            "abstract": [
                "The work presented in this thesis studies various nature-inspired inductive biases in the domain of model-free and model-based reinforcement learning with the goal of designing AI agents that act more efficiently and autonomously in natural environments. The domain of robotic manipulation tasks is particularly interesting as it involves non-trivial system dynamics and requires abundant planning and reasoning. The inductive biases under investigation are primarily inspired by intelligent agents found in nature, such as humans and other animals. The primary sources of inspiration are as follows. (1) Hierarchically organized and specialized cortical structures facilitating efficient skills learning. (2) The self-organized playing of children to form intuitive theories and models about the world. (3) Structured exploration strategies based on various forms of intrinsic motivation and long-lasting temporal correlations in motor commands. (4) Imitation Learning. (5) Uncertainty-aware planning of motor commands in imagined models of a non-deterministic world. Consequently, this work continues a long history of ideas and research efforts that take inspiration from nature to build more competent AI agents. These efforts culminated in research fields such as hierarchical reinforcement learning, developmental robotics, intrinsically motivated reinforcement learning, and representation learning. This work builds on the ideas that were advanced in these fields. It combines them with model-free and model-based reinforcement learning methods to solve challenging robotic manipulation tasks from scratch. Empirical studies are carried out to support the hypothesis that nature-inspired inductive biases might be an essential building block in designing more competent AI agents.",
                "Die in dieser Dissertation vorgestellten Arbeiten studieren verschiedene von der Natur inspirierte induktive Verzerrungen im Kontext von modellfreiem und modellbasiertem selbstverst\u00e4rkenden Lernen, mit dem Ziel, KI Agenten zu entwerfen, die effizient und autonom in der realen Welt handeln. Dabei sind von Robotern zu bew\u00e4ltigende Objektmanipulationsaufgaben von besonderem Interesse, da die zeitliche Entwicklung dieser dynamischen Systeme nicht trivial ist und Manipulationsaufgaben schwierige Planungsprobleme darstellen. Die betrachteten induktiven Verzerrungen sind haupts\u00e4chlich von in der Natur zu findenden intelligenten Agenten, wie Tiere und Menschen, inspiriert. Die prim\u00e4ren Inspirationsquellen sind wie folgt. (1) Hierarchisch organisierte und spezialisierte kortikale Strukturen, die die effektive Erlernung von F\u00e4higkeiten unterst\u00fctzen. (2) Das selbstorganisierte Spielen von Kindern zum Zwecke der Formung intuitiver Modelle und Theorien \u00fcber die Welt. (3) Strukturierte Explorationsstrategien basierend auf unterschiedliche Formen von intrinsischer Motivation und lang anhaltender zeitlicher Korrelationen in motorischen Befehlen. (4) Imitationslernen. (5) Die Planung von Aktionssequenzen unter der Ber\u00fccksichtigung von Unsicherheiten in mentalen Modellen der nichtdeterministischen Welt. Diese Arbeit ist die Fortsetzung einer langen Historie von Ideen und Forschungsbem\u00fchungen, die Inspiration aus der Natur ziehen, um kompetentere KI Agenten zu entwickeln. Die Bem\u00fchungen in diesen Forschungsfeldern m\u00fcndeten in der Ausbildung verschiedener Forschungsfelder wie hierarchisches selbstverst\u00e4rkendes Lernen, Entwicklungsrobotik, intrinsisch motiviertes selbstverst\u00e4rkendes Lernen und Repr\u00e4sentationslernen. Diese Arbeit baut auf den in diesen Feldern entwickelten Ideen und Konzepten auf und kombiniert diese mit Methoden von modellfreiem und modellbasiertem selbstverst\u00e4rkenden Lernen, um es Robotern zu erm\u00f6glichen, herausfordernde Objektmanipulationsaufgaben von Grund auf zu l\u00f6sen. Die Hypothese, dass von der Natur inspirierte induktive Verzerrungen einen essenziellen Beitrag zur Erschaffung kompetenterer KI Agenten liefern k\u00f6nnten, wird dabei durch zahlreiche empirische Studien unterst\u00fctzt."
            ],
            "contributor": "Technische Informationsbibliothek (TIB)",
            "creator": [
                "gnd:1278060960",
                "gnd:36187-2"
            ],
            "isPartOf": "(collectioncode)GBV-ODiss",
            "issued": "2022",
            "language": "http://id.loc.gov/vocabulary/iso639-1/en",
            "license": "open access",
            "medium": "rda:termList/RDACarrierType/1018",
            "isLike": "doi:10.15496/publikation-76028",
            "P60163": "T\u00fcbingen"
        }
    ],
    "@id": "urn:x-arq:DefaultGraphNode",
    "@context": {
        "contributor": "http://purl.org/dc/terms/contributor",
        "medium": {
            "@id": "http://purl.org/dc/terms/medium",
            "@type": "@id"
        },
        "license": "http://purl.org/dc/terms/license",
        "description": "http://purl.org/dc/elements/1.1/description",
        "creator": {
            "@id": "http://purl.org/dc/terms/creator",
            "@type": "@id"
        },
        "subject": "http://purl.org/dc/elements/1.1/subject",
        "identifier": "http://purl.org/dc/elements/1.1/identifier",
        "abstract": "http://purl.org/dc/terms/abstract",
        "isPartOf": "http://purl.org/dc/terms/isPartOf",
        "isLike": {
            "@id": "http://umbel.org/umbel#isLike",
            "@type": "@id"
        },
        "issued": "http://purl.org/dc/terms/issued",
        "title": "http://purl.org/dc/elements/1.1/title",
        "P1053": "http://iflastandards.info/ns/isbd/elements/P1053",
        "P60163": "http://www.rdaregistry.info/Elements/u/#P60163",
        "language": {
            "@id": "http://purl.org/dc/terms/language",
            "@type": "@id"
        },
        "sameAs": "http://www.w3.org/2002/07/owl#sameAs",
        "umbel": "http://umbel.org/umbel#",
        "rdau": "http://www.rdaregistry.info/Elements/u/#",
        "owl": "http://www.w3.org/2002/07/owl#",
        "dcterms": "http://purl.org/dc/terms/",
        "bibo": "http://purl.org/ontology/bibo/",
        "rdam": "http://www.rdaregistry.info/Elements/m/#",
        "gnd": "http://d-nb.info/gnd/",
        "isbd": "http://iflastandards.info/ns/isbd/elements/",
        "rda": "http://rdvocab.info/",
        "doi": "https://doi.org/"
    }
}