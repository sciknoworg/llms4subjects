{
    "@graph": [
        {
            "@id": "gnd:1176169416",
            "sameAs": "B\u00f6hm, Anton"
        },
        {
            "@id": "https://www.tib.eu/de/suchen/id/TIBKAT%3A1780451873",
            "@type": "bibo:Thesis",
            "P1053": "1 Online-Ressource (148 Seiten)",
            "description": "Illustrationen, Diagramme",
            "identifier": [
                "(doi)10.6094/UNIFR/221808",
                "(contract)FRUB-opus-221808",
                "(ppn)1780451873",
                "(firstid)DNB:1242910794"
            ],
            "subject": [
                "(classificationName=ddc-dbn)004",
                "(classificationName=linseach:mapping)inf",
                "(classificationName=ddc)006.37"
            ],
            "title": "Instance segmentation of microscopy images : development of deep learning image analysis tools",
            "abstract": [
                "Abstract: In this work, we develop general deep-learning tools for detection, segmentation and tracking of microscopical objects. In doing so, we put focus on the special case: accurate segmentation of densely overlapping translucent objects. In this context, we present two approaches.<br><br>In the first one, we transform 2D segmentation masks to a high-dimensional space. As result, the masks have a larger distance to each other and become spatially separable. The resulting high-dimensional masks' representation can be directly used for training. During inference, we undo the transformation in a post-processing step which yields the final 2D instance masks.<br><br>The second one is an encoder-decoder approach: a network encodes objects to deep-features which are then decoded by a different network to the final objects' masks. With this approach, we achieve a strong performance on all tested datasets and tasks without using heavy pre- and post-processing steps.<br><br>We also propose several modifications to both approaches and extend the second one by the temporal dimension: It allows us to successfully track and segment beside moving and overlapping also dividing objects",
                "Abstract: In dieser Arbeit besch\u00e4ftigen wir uns mit der Entwicklung genereller Deep-Learning Verfahren zur Detektion, Segmentierung und Verfolgung mikroskopischer Objekte. Dabei legen wir den Fokus auf den Sonderfall: akkurate Segmentierung von sich stark \u00fcberlappenden transluzenten Objekten. In diesem Kontext pr\u00e4sentieren wir zwei L\u00f6sungsans\u00e4tze.<br><br>Bei dem ersten Verfahren transformieren wir 2D Segmentierungsmasken in einen Raum h\u00f6herer Dimension. Als Ergebnis haben diese einen gr\u00f6\u00dferen Abstand zueinander und werden somit r\u00e4umlich trennbar. Die resultierende hochdimensionale Maskenrepr\u00e4sentation kann direkt zum Training verwendet werden. W\u00e4hrend der Inferenzphase machen wir die Transformation in einem Nachbearbeitungsschritt r\u00fcckg\u00e4ngig und gewinnen somit die finalen 2D Objektmasken zur\u00fcck.<br><br>Bei dem zweiten L\u00f6sungsansatz geht es um ein Zwei-Phasen Verfahren. Dabei enkodiert im ersten Schritt ein Netzwerk Objekte zu Deep-Features, welche dann im zweiten Schritt durch ein anderes Netzwerk zu den finalen Objektmasken dekodiert werden. Mit diesem Ansatz erreichen wir eine beachtliche Leistung auf allen von uns getesteten Datens\u00e4tzen und Aufgaben, ohne dabei schwerwiegende Vor- und Nachbearbeitungschritte zu nutzen.<br><br>Wir schlagen auch einige Verbesserungen der beiden Ans\u00e4tze vor und erweitern den zweiten Ansatz um die zeitliche Komponente: Das erlaubt uns, neben sich bewegenden und \u00fcberlappenden Objekten auch sich teilende Objekte erfolgreich zu verfolgen und zu segmentieren"
            ],
            "contributor": "Technische Informationsbibliothek (TIB)",
            "creator": "gnd:1176169416",
            "isPartOf": "(collectioncode)GBV-ODiss",
            "issued": "2021",
            "language": "http://id.loc.gov/vocabulary/iso639-1/en",
            "license": "open access",
            "medium": "rda:termList/RDACarrierType/1018",
            "isLike": "doi:10.6094/UNIFR/221808",
            "P60163": "Freiburg im Breisgau"
        }
    ],
    "@id": "urn:x-arq:DefaultGraphNode",
    "@context": {
        "sameAs": "http://www.w3.org/2002/07/owl#sameAs",
        "isLike": {
            "@id": "http://umbel.org/umbel#isLike",
            "@type": "@id"
        },
        "identifier": "http://purl.org/dc/elements/1.1/identifier",
        "subject": "http://purl.org/dc/elements/1.1/subject",
        "medium": {
            "@id": "http://purl.org/dc/terms/medium",
            "@type": "@id"
        },
        "issued": "http://purl.org/dc/terms/issued",
        "title": "http://purl.org/dc/elements/1.1/title",
        "license": "http://purl.org/dc/terms/license",
        "abstract": "http://purl.org/dc/terms/abstract",
        "description": "http://purl.org/dc/elements/1.1/description",
        "isPartOf": "http://purl.org/dc/terms/isPartOf",
        "P60163": "http://www.rdaregistry.info/Elements/u/#P60163",
        "contributor": "http://purl.org/dc/terms/contributor",
        "language": {
            "@id": "http://purl.org/dc/terms/language",
            "@type": "@id"
        },
        "creator": {
            "@id": "http://purl.org/dc/terms/creator",
            "@type": "@id"
        },
        "P1053": "http://iflastandards.info/ns/isbd/elements/P1053",
        "umbel": "http://umbel.org/umbel#",
        "rdau": "http://www.rdaregistry.info/Elements/u/#",
        "owl": "http://www.w3.org/2002/07/owl#",
        "dcterms": "http://purl.org/dc/terms/",
        "bibo": "http://purl.org/ontology/bibo/",
        "rdam": "http://www.rdaregistry.info/Elements/m/#",
        "gnd": "http://d-nb.info/gnd/",
        "isbd": "http://iflastandards.info/ns/isbd/elements/",
        "rda": "http://rdvocab.info/",
        "doi": "https://doi.org/"
    }
}