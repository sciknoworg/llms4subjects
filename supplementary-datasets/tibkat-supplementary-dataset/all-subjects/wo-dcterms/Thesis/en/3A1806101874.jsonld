{
    "@graph": [
        {
            "@id": "gnd:1261934989",
            "sameAs": "Kunczik, Leonhard"
        },
        {
            "@id": "https://www.tib.eu/de/suchen/id/TIBKAT%3A1806101874",
            "@type": "bibo:Thesis",
            "P1053": "1 Online-Ressource (xviii, 134 Seiten)",
            "description": [
                "Campusweiter Zugriff (Universit\u00e4t Hannover) - Vervielf\u00e4ltigungen (z.B. Kopien, Downloads) sind nur von einzelnen Kapiteln oder Seiten und nur zum eigenen wissenschaftlichen Gebrauch erlaubt. Keine Weitergabe an Dritte. Kein systematisches Downloaden durch Robots.",
                "Illustrationen, Diagramme",
                "Erworben aus Studienqualit\u00e4tsmitteln"
            ],
            "identifier": [
                "(ppn)1806101874",
                "(isbn13)9783658376161",
                "(doi)10.1007/978-3-658-37616-1",
                "(firstid)KEP:078627435"
            ],
            "publisher": "Springer Vieweg",
            "subject": [
                "(classificationName=ddc)006.31",
                "Data protection.",
                "Computer crimes.",
                "(classificationName=linseach:mapping)inf",
                "Machine learning."
            ],
            "title": "Reinforcement learning with hybrid quantum approximation in the NISQ context",
            "abstract": [
                "Motivation: Complex Attacker-Defender Scenarios - The eternal con\ufb02ict., The Information Game - A special Attacker-Defender Scenario., Reinforcement Learning and Bellman\u2019s Principle of Optimality., Quantum Reinforcement Learning - Connecting Reinforcement Learning and Quantum Computing -- Approximation in Quantum Computing -- Advanced Quantum Policy Approximation in Policy Gradient Rein-forcement Learning -- Applying Quantum REINFORCE to the Information Game -- Evaluating quantum REINFORCE on IBM\u2019s Quantum Hardware -- Future Steps in Quantum Reinforcement Learning for Complex Scenarios -- Conclusion.",
                "This book explores the combination of Reinforcement Learning and Quantum Computing in the light of complex attacker-defender scenarios. Reinforcement Learning has proven its capabilities in different challenging optimization problems and is now an established method in Operations Research. However, complex attacker-defender scenarios have several characteristics that challenge Reinforcement Learning algorithms, requiring enormous computational power to obtain the optimal solution. The upcoming field of Quantum Computing is a promising path for solving computationally complex problems. Therefore, this work explores a hybrid quantum approach to policy gradient methods in Reinforcement Learning. It proposes a novel quantum REINFORCE algorithm that enhances its classical counterpart by Quantum Variational Circuits. The new algorithm is compared to classical algorithms regarding the convergence speed and memory usage on several attacker-defender scenarios with increasing complexity. In addition, to study its applicability on today's NISQ hardware, the algorithm is evaluated on IBM's quantum computers, which is accompanied by an in-depth analysis of the advantages of Quantum Reinforcement Learning. About the author Leonhard Kunczik obtained his Dr. rer. nat. in 2021 in Quantum Reinforcement Learning from the Universit\u00e4t der Bundeswehr M\u00fcnchen as a member of the COMTESSA research group. Now, he continues his research as a project leader at the forefront of Quantum Machine Learning and Optimization in the context of Operations Research and Cyber Security."
            ],
            "contributor": "Technische Informationsbibliothek (TIB)",
            "creator": "gnd:1261934989",
            "isPartOf": [
                "(collectioncode)ZDB-2-SXMS",
                "(collectioncode)ZDB-2-SEB",
                "(collectioncode)ZDB-2-SMA"
            ],
            "issued": "2022",
            "language": "http://id.loc.gov/vocabulary/iso639-1/en",
            "license": "commercial licence",
            "medium": "rda:termList/RDACarrierType/1018",
            "isLike": "doi:10.1007/978-3-658-37616-1",
            "P60163": "Wiesbaden"
        }
    ],
    "@id": "urn:x-arq:DefaultGraphNode",
    "@context": {
        "isPartOf": "http://purl.org/dc/terms/isPartOf",
        "subject": "http://purl.org/dc/elements/1.1/subject",
        "description": "http://purl.org/dc/elements/1.1/description",
        "identifier": "http://purl.org/dc/elements/1.1/identifier",
        "title": "http://purl.org/dc/elements/1.1/title",
        "license": "http://purl.org/dc/terms/license",
        "medium": {
            "@id": "http://purl.org/dc/terms/medium",
            "@type": "@id"
        },
        "issued": "http://purl.org/dc/terms/issued",
        "P60163": "http://www.rdaregistry.info/Elements/u/#P60163",
        "contributor": "http://purl.org/dc/terms/contributor",
        "creator": {
            "@id": "http://purl.org/dc/terms/creator",
            "@type": "@id"
        },
        "abstract": "http://purl.org/dc/terms/abstract",
        "language": {
            "@id": "http://purl.org/dc/terms/language",
            "@type": "@id"
        },
        "isLike": {
            "@id": "http://umbel.org/umbel#isLike",
            "@type": "@id"
        },
        "publisher": "http://purl.org/dc/elements/1.1/publisher",
        "P1053": "http://iflastandards.info/ns/isbd/elements/P1053",
        "sameAs": "http://www.w3.org/2002/07/owl#sameAs",
        "umbel": "http://umbel.org/umbel#",
        "rdau": "http://www.rdaregistry.info/Elements/u/#",
        "owl": "http://www.w3.org/2002/07/owl#",
        "dcterms": "http://purl.org/dc/terms/",
        "bibo": "http://purl.org/ontology/bibo/",
        "rdam": "http://www.rdaregistry.info/Elements/m/#",
        "gnd": "http://d-nb.info/gnd/",
        "isbd": "http://iflastandards.info/ns/isbd/elements/",
        "rda": "http://rdvocab.info/",
        "doi": "https://doi.org/"
    }
}