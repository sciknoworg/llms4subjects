{
    "@graph": [
        {
            "@id": "gnd:1268389226",
            "sameAs": "\u00dcnal, Ali Burak"
        },
        {
            "@id": "gnd:36187-2",
            "sameAs": "Eberhard Karls Universit\u00e4t T\u00fcbingen"
        },
        {
            "@id": "https://www.tib.eu/de/suchen/id/TIBKAT%3A1814676759",
            "@type": "bibo:Thesis",
            "P1053": "1 Online-Ressource (XVII, 142 Seiten)",
            "description": "Illustrationen",
            "identifier": [
                "(doi)10.15496/publikation-71420",
                "(ppn)1814676759",
                "(firstid)KXP:1814676759"
            ],
            "subject": [
                "(classificationName=ddc)006.31",
                "(classificationName=ddc-dbn)004",
                "(classificationName=linseach:mapping)inf"
            ],
            "title": "Towards a complete privacy preserving machine learning pipeline",
            "abstract": [
                "Machine learning has proven its success on various problems from many different domains. Different machine learning algorithms use different approaches to capture the underlying patterns in the data. Even though the amount varies between the machine learning algorithms, they require sufficient amounts of data to recognize those patterns. One of the easiest ways to meet this need of the machine learning algorithms is to use multiple sources generating the same type of data. Such a solution is feasible considering that the speed of data generation and the number of sources generating these data have been increasing in parallel to the developments in technology. One can easily satisfy the desire of the machine learning algorithms for data using these sources. However, this can cause a privacy leakage. The data generated by these sources may contain sensitive information that can be used for undesirable purposes. Therefore, although the machine learning algorithms demand for data, the sources may not be willing or even allowed to share their data. A similar dilemma occurs when the data owner wants to extract useful information from the data by using machine learning algorithms but it does not have enough computational power or knowledge. In this case, the data source may want to outsource this task to external parties that offer machine learning algorithms as a service. Similarly, in this case, the sensitive information in the data can be the decisive factor for the owner not to choose outsourcing, which then ends up with non-utilized data for the owner. In order to address these kinds of dilemmas and issues, this thesis aims to come up with a complete privacy preserving machine learning pipeline. It introduces several studies that address different phases of the pipeline so that all phases of a machine learning algorithm can be performed privately. One of these phases addressed in this thesis is training of a machine learning algorithm. The privacy preserving training of kernel-based machine learning algorithms are addressed in several different works with different cryptographic techniques, one of which is a our newly developed encryption scheme. The different techniques have different advantages over the others. Furthermore, this thesis introduces our study addressing the testing phase of not only the kernel-based machine learning algorithms but also a special type of recurrent neural network, namely recurrent kernel networks, which is the first study performing such an inference, without compromising privacy. To enable the privacy preserving inference on recurrent kernel networks, this thesis introduces a framework, called CECILIA, with two novel functions, which are the exponential and the inverse square root of the Gram matrix, and efficient versions of the existing functions, which are the multiplexer and the most significant bit. Using this framework and other approaches in the corresponding studies, it is possible to perform privacy preserving inference on various pre-trained machine learning algorithms. Besides the training and testing of machine learning algorithms in a privacy preserving way, this thesis also presents a work that aims to evaluate the performance of machine learning algorithms without sacrificing privacy. This work employs CECILIA to realize the area under curve calculation for two different curve-based evaluations, namely the receiver operating characteristic curve and the precision-recall curve, in a privacy preserving manner. All the proposed approaches are shown to be correct using several machine learning tasks and evaluated for the scalability of the parameters of the corresponding system/algorithm using synthetic data. The results show that the privacy preserving training and testing of kernel-based machine learning algorithms is possible with different settings and the privacy preserving inference on a pre-trained recurrent kernel network is feasible using CECILIA. Additionally, CECILIA also allows the exact area under curve computation to evaluate the performance of a machine learning algorithm without compromising privacy.",
                "Das maschinelle Lernen hat seinen Erfolg bei verschiedenen Problemen in vielen unterschiedlichen Bereichen bewiesen. Verschiedene Algorithmen f\u00fcr maschinelles Lernen verwenden unterschiedliche Ans\u00e4tze, um die zugrunde liegenden Muster in den Daten zu erfassen. Auch wenn die Menge der Daten bei den verschiedenen Algorithmen f\u00fcr maschinelles Lernen unterschiedlich ist, ben\u00f6tigen sie doch eine ausreichende Menge an Daten, um diese Muster zu erkennen. Eine der einfachsten M\u00f6glichkeiten, diesen Bedarf der Algorithmen f\u00fcr maschinelles Lernen zu decken, ist die Verwendung mehrerer Quellen, die die gleiche Art von Daten erzeugen. Eine solche L\u00f6sung ist machbar, wenn man bedenkt, dass die Geschwindigkeit der Datengenerierung und die Anzahl der Quellen, die diese Daten generieren, parallel zu den Entwicklungen in der Technologie gestiegen sind. Der Wunsch der Algorithmen des maschinellen Lernens nach Daten kann mit Hilfe dieser Quellen leicht erf\u00fcllt werden. Dies kann jedoch zu einer Beeintr\u00e4chtigung der Privatsph\u00e4re f\u00fchren. Die von diesen Quellen erzeugten Daten k\u00f6nnen sensible Informationen enthalten, die f\u00fcr unerw\u00fcnschte Zwecke verwendet werden k\u00f6nnen. Obwohl die Algorithmen f\u00fcr maschinelles Lernen Daten ben\u00f6tigen, sind die Quellen daher m\u00f6glicherweise nicht bereit, ihre Daten weiterzugeben. Ein \u00e4hnliches Dilemma tritt auf, wenn der/die Dateneigent\u00fcmer*in mit Hilfe von Algorithmen f\u00fcr maschinelles Lernen n\u00fctzliche Informationen aus den Daten extrahieren m\u00f6chte, aber nicht \u00fcber gen\u00fcgend Rechenleistung oder Wissen verf\u00fcgt. In diesem Fall kann diese Aufgabe m\u00f6glicherweise an externe Parteien ausgelagert werden, die Algorithmen f\u00fcr maschinelles Lernen als Dienstleistung anbieten. Auch in diesem Fall k\u00f6nnen die sensiblen Informationen in den Daten der entscheidende Faktor f\u00fcr den/die Eigent\u00fcmer*in sein, sich nicht f\u00fcr eine Auslagerung zu entscheiden, was dann dazu f\u00fchrt, dass die Daten f\u00fcr den/die Eigent\u00fcmer*in nicht genutzt werden. Um diese Art von Dilemmata und Problemen anzugehen, zielt diese Arbeit darauf ab, eine vollst\u00e4ndige Pipeline f\u00fcr maschinelles Lernen unter Wahrung der Privatsph\u00e4re zu entwickeln. Es werden mehrere Studien vorgestellt, die sich mit verschiedenen Phasen der Pipeline befassen, so dass alle Phasen eines Algorithmus f\u00fcr maschinelles Lernen unter Wahrung der Privatsph\u00e4re durchgef\u00fchrt werden k\u00f6nnen. Eine dieser Phasen, die in dieser Arbeit behandelt wird, ist das Training eines maschinellen Lernalgorithmus. Das Training von kernbasierten maschinellen Lernalgorithmen unter Wahrung der Privatsph\u00e4re wird in verschiedenen Arbeiten mit unterschiedlichen kryptographischen Techniken behandelt, von denen eine ein von aus entwickeltes neuartiges Verschl\u00fcsselungsverfahren ist. Diese haben jeweils unterschiedliche Vorteile gegen\u00fcber den anderen. Dar\u00fcber hinaus werden in dieser Arbeit Studien vorgestellt, die sich mit der Testphase nicht nur kernelbasierter maschineller Lernalgorithmen befassen, sondern auch mit einem speziellen Typ rekurrenter neuronaler Netze, n\u00e4mlich den rekurrenten Kernnetzen, das die erste Studie ist, die eine solche Inferenz durchf\u00fchrt, ohne die Privatsph\u00e4re zu gef\u00e4hrden. Um eine datenschutzkonforme Inferenz auf rekurrenten Kernnetzen zu erm\u00f6glichen, wird in dieser Arbeit ein Framework mit dem Namen CECILIA eingef\u00fchrt, das zwei neuartige Funktionen enth\u00e4lt, n\u00e4mlich die Exponentialfunktion und die inverse Quadratwurzel der Gram-Matrix, sowie effiziente Versionen etablierter Funktionen, Multiplexer und least significant bit. Unter Verwendung dieses Frameworks und anderer Ans\u00e4tze in den entsprechenden Studien ist es m\u00f6glich, datenschutzkonforme Inferenzen f\u00fcr verschiedene vortrainierte Algorithmen des maschinellen Lernens durchzuf\u00fchren. Neben dem Training und Testen von maschinellen Lernalgorithmen unter Wahrung der Privatsph\u00e4re wird in dieser Arbeit auch eine Studie vorgestellt, die darauf abzielt, die Leistung von maschinellen Lernalgorithmen zu bewerten, ohne die Privatsph\u00e4re zu gef\u00e4hrden. In dieser Arbeit wird CECILIA eingesetzt, um die Berechnung der Fl\u00e4che unter der Kurve f\u00fcr zwei verschiedene kurrenbasierte Auswertungen, n\u00e4mlich die Receiver-Operating-Characteristic-Kurve und die Precision-Recall-Kurve, auf eine datenschutzfreundliche Weise zu realisieren. Alle vorgeschlagenen Ans\u00e4tze werden anhand verschiedener Aufgaben des maschinellen Lernens auf ihre Korrektheit gepr\u00fcft und auf ihre Skalierbarkeit mit den Parametern des entsprechenden Systems/Algorithmus unter Verwendung synthetischer Daten untersucht. Die Ergebnisse zeigen, dass das Training und Testen von kernbasierten maschinellen Lernalgorithmen unter Wahrung der Privatsph\u00e4re mit verschiedenen Einstellungen m\u00f6glich ist und, dass die Inferenz mit einem vortrainierten rekurrenten Kernnetzwerk unter Verwendung von CECILIA m\u00f6glich ist. Dar\u00fcber hinaus erm\u00f6glicht CECILIA auch die exakte Berechnung der Fl\u00e4che unter der Kurve, um die Leistung eines maschinellen Lernalgorithmus zu bewerten, ohne die Privatsph\u00e4re zu beeintr\u00e4chtigen."
            ],
            "contributor": "Technische Informationsbibliothek (TIB)",
            "creator": [
                "gnd:36187-2",
                "gnd:1268389226"
            ],
            "isPartOf": "(collectioncode)GBV-ODiss",
            "issued": "2022",
            "language": "http://id.loc.gov/vocabulary/iso639-1/en",
            "license": "open access",
            "medium": "rda:termList/RDACarrierType/1018",
            "isLike": "doi:10.15496/publikation-71420",
            "P60163": "T\u00fcbingen"
        }
    ],
    "@id": "urn:x-arq:DefaultGraphNode",
    "@context": {
        "sameAs": "http://www.w3.org/2002/07/owl#sameAs",
        "identifier": "http://purl.org/dc/elements/1.1/identifier",
        "license": "http://purl.org/dc/terms/license",
        "description": "http://purl.org/dc/elements/1.1/description",
        "creator": {
            "@id": "http://purl.org/dc/terms/creator",
            "@type": "@id"
        },
        "title": "http://purl.org/dc/elements/1.1/title",
        "subject": "http://purl.org/dc/elements/1.1/subject",
        "P1053": "http://iflastandards.info/ns/isbd/elements/P1053",
        "issued": "http://purl.org/dc/terms/issued",
        "isPartOf": "http://purl.org/dc/terms/isPartOf",
        "abstract": "http://purl.org/dc/terms/abstract",
        "isLike": {
            "@id": "http://umbel.org/umbel#isLike",
            "@type": "@id"
        },
        "P60163": "http://www.rdaregistry.info/Elements/u/#P60163",
        "medium": {
            "@id": "http://purl.org/dc/terms/medium",
            "@type": "@id"
        },
        "contributor": "http://purl.org/dc/terms/contributor",
        "language": {
            "@id": "http://purl.org/dc/terms/language",
            "@type": "@id"
        },
        "umbel": "http://umbel.org/umbel#",
        "rdau": "http://www.rdaregistry.info/Elements/u/#",
        "owl": "http://www.w3.org/2002/07/owl#",
        "dcterms": "http://purl.org/dc/terms/",
        "bibo": "http://purl.org/ontology/bibo/",
        "rdam": "http://www.rdaregistry.info/Elements/m/#",
        "gnd": "http://d-nb.info/gnd/",
        "isbd": "http://iflastandards.info/ns/isbd/elements/",
        "rda": "http://rdvocab.info/",
        "doi": "https://doi.org/"
    }
}