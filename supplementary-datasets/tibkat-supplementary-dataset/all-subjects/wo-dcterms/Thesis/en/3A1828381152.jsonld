{
    "@graph": [
        {
            "@id": "gnd:1283888467",
            "sameAs": "Meyer, Johannes"
        },
        {
            "@id": "gnd:36187-2",
            "sameAs": "Eberhard Karls Universit\u00e4t T\u00fcbingen"
        },
        {
            "@id": "https://www.tib.eu/de/suchen/id/TIBKAT%3A1828381152",
            "@type": "bibo:Thesis",
            "P1053": "1 Online-Ressource (xx, v, 249 Seiten)",
            "description": "Illustrationen",
            "identifier": [
                "(firstid)KXP:1828381152",
                "(ppn)1828381152"
            ],
            "subject": [
                "Erweiterte Realit\u00e4t",
                "Laser",
                "Optik",
                "(classificationName=linseach:mapping)cet",
                "(classificationName=linseach:mapping)mas",
                "Sensor",
                "(classificationName=ddc-dbn)681.2",
                "Wechselwirkung",
                "(classificationName=ddc-dbn)670"
            ],
            "title": "Towards energy efficient mobile eye tracking for AR glasses through optical sensor technology",
            "abstract": "After the introduction of smartphones and smartwatches, Augmented Reality (AR) glasses are considered the next breakthrough in the field of wearables. While the transition from smartphones to smartwatches was based mainly on established display technologies, the display technology of AR glasses presents a technological challenge. Many display technologies, such as retina projectors, are based on continuous adaptive control of the display based on the user\u2019s pupil position. Furthermore, head-mounted systems require an adaptation and extension of established interaction concepts to provide the user with an immersive experience. Eye-tracking is a crucial technology to help AR glasses achieve a breakthrough through optimized display technology and gaze-based interaction concepts. Available eye-tracking technologies, such as Video Oculography (VOG), do not meet the requirements of AR glasses, especially regarding power consumption, robustness, and integrability. To further overcome these limitations and push mobile eye-tracking for AR glasses forward, novel laser-based eye-tracking sensor technologies are researched in this thesis. The thesis contributes to a significant scientific advancement towards energy-efficientmobile eye-tracking for AR glasses. In the first part of the thesis, novel scanned laser eye-tracking sensor technologies for AR glasses with retina projectors as display technology are researched. The goal is to solve the disadvantages of VOG systems and to enable robust eye-tracking and efficient ambient light and slippage through optimized sensing methods and algorithms. The second part of the thesis researches the use of static Laser Feedback Interferometry (LFI) sensors as low power always-on sensor modality for detection of user interaction by gaze gestures and context recognition through Human Activity Recognition (HAR) for AR glasses. The static LFI sensors can measure the distance to the eye and the eye\u2019s surface velocity with an outstanding sampling rate. Furthermore, they offer high integrability regardless of the display technology. In the third part of the thesis, a model-based eye-tracking approach is researched based on the static LFI sensor technology. The approach leads to eye-tracking with an extremely high sampling rate by fusing multiple LFI sensors, which enables methods for display resolution enhancement such as foveated rendering for AR glasses and Virtual Reality (VR) systems. The scientific contributions of this work lead to a significant advance in the field of mobile eye-tracking for AR glasses through the introduction of novel sensor technologies that enable robust eye tracking in uncontrolled environments in particular. Furthermore, the scientific contributions of this work have been published in internationally renowned journals and conferences.",
            "contributor": "Technische Informationsbibliothek (TIB)",
            "creator": [
                "gnd:1283888467",
                "gnd:36187-2"
            ],
            "isPartOf": "(collectioncode)GBV-ODiss",
            "issued": "2022",
            "language": "http://id.loc.gov/vocabulary/iso639-1/en",
            "license": "open access",
            "medium": "rda:termList/RDACarrierType/1018",
            "P60163": "T\u00fcbingen"
        }
    ],
    "@id": "urn:x-arq:DefaultGraphNode",
    "@context": {
        "description": "http://purl.org/dc/elements/1.1/description",
        "creator": {
            "@id": "http://purl.org/dc/terms/creator",
            "@type": "@id"
        },
        "issued": "http://purl.org/dc/terms/issued",
        "abstract": "http://purl.org/dc/terms/abstract",
        "license": "http://purl.org/dc/terms/license",
        "subject": "http://purl.org/dc/elements/1.1/subject",
        "contributor": "http://purl.org/dc/terms/contributor",
        "identifier": "http://purl.org/dc/elements/1.1/identifier",
        "isPartOf": "http://purl.org/dc/terms/isPartOf",
        "medium": {
            "@id": "http://purl.org/dc/terms/medium",
            "@type": "@id"
        },
        "language": {
            "@id": "http://purl.org/dc/terms/language",
            "@type": "@id"
        },
        "title": "http://purl.org/dc/elements/1.1/title",
        "P60163": "http://www.rdaregistry.info/Elements/u/#P60163",
        "P1053": "http://iflastandards.info/ns/isbd/elements/P1053",
        "sameAs": "http://www.w3.org/2002/07/owl#sameAs",
        "umbel": "http://umbel.org/umbel#",
        "rdau": "http://www.rdaregistry.info/Elements/u/#",
        "owl": "http://www.w3.org/2002/07/owl#",
        "dcterms": "http://purl.org/dc/terms/",
        "bibo": "http://purl.org/ontology/bibo/",
        "rdam": "http://www.rdaregistry.info/Elements/m/#",
        "gnd": "http://d-nb.info/gnd/",
        "isbd": "http://iflastandards.info/ns/isbd/elements/",
        "rda": "http://rdvocab.info/",
        "doi": "https://doi.org/"
    }
}