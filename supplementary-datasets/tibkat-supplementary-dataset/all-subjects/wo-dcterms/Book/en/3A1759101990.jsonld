{
    "@graph": [
        {
            "@id": "https://www.tib.eu/de/suchen/id/TIBKAT%3A1759101990",
            "@type": "bibo:Book",
            "P1053": "1 Online-Ressource (1 electronic text (xvi, 194 p.))",
            "contributor": "Kolobov, Andrey",
            "creator": "Mausam",
            "description": [
                "Campusweiter Zugriff (Universit\u00e4t Hannover) - Vervielf\u00e4ltigungen (z.B. Kopien, Downloads) sind nur von einzelnen Kapiteln oder Seiten und nur zum eigenen wissenschaftlichen Gebrauch erlaubt. Keine Weitergabe an Dritte. Kein systematisches Downloaden durch Robots.",
                "ill., digital file"
            ],
            "identifier": [
                "(isbn13)9781608458875",
                "(firstid)KEP:063070731",
                "(ppn)1759101990"
            ],
            "publisher": "Morgan & Claypool",
            "subject": [
                "Artificial intelligence",
                "(classificationName=ddc)006.3",
                "Markov processes",
                "(classificationName=linseach:mapping)inf",
                "(classificationName=loc)Q335"
            ],
            "title": "Planning with Markov decision processes : an AI perspective",
            "abstract": [
                "7. Advanced notes -- 7.1 MDPs with continuous or hybrid states -- 7.2 MDP with concurrency and durative actions -- 7.3 Relational MDPs -- 7.4 Generalized stochastic shortest path MDPs -- 7.5 Other models -- 7.6 Issues in probabilistic planning -- 7.7 Summary -- Bibliography.",
                "4. Heuristic search algorithms -- 4.1 Heuristic search and SSP MDPs -- 4.2 FIND-and-REVISE: a schema for heuristic search -- 4.3 LAO and extensions -- 4.4 RTDP and extensions -- 4.5 Heuristics and transition graph pruning -- 4.6 Computing admissible heuristics -- 4.7 Heuristic search and dead ends --",
                "3. Fundamental algorithms -- 3.1 A brute-force algorithm -- 3.2 Policy evaluation -- 3.3 Policy iteration -- 3.4 Value iteration -- 3.5 Prioritization in value iteration -- 3.6 Partitioned value iteration -- 3.7 Linear programming formulation -- 3.8 Infinite-horizon discounted-reward MDPs -- 3.9 Finite-horizon MDPs -- 3.10 MDPs with dead ends --",
                "Preface -- 1. Introduction -- 1.1 Characteristics of an MDP -- 1.2 Connections with different fields -- 1.3 Overview of this book --",
                "6. Approximation algorithms -- 6.1 Determinization-based techniques -- 6.2 Sampling-based techniques -- 6.3 Heuristic search with inadmissible heuristics -- 6.4 Dimensionality reduction-based techniques -- 6.5 Hierarchical planning -- 6.6 Hybridized planning -- 6.7 A comparison of different algorithms --",
                "2. MDPs -- 2.1 Markov decision processes: definition -- 2.2 Solutions of an MDP -- 2.3 Solution existence -- 2.4 Stochastic shortest-path MDPs -- 2.5 Factored MDPs -- 2.6 Complexity of solving MDPs --",
                "Markov Decision Processes (MDPs) are widely popular in Artificial Intelligence for modeling sequential decision-making scenarios with probabilistic dynamics. They are the framework of choice when designing an intelligent agent that needs to act for long periods of time in an environment where its actions could have uncertain outcomes.MDPs are actively researched in two related subareas of AI, probabilistic planning and reinforcement learning. Probabilistic planning assumes known models for the agent's goals and domain dynamics, and focuses on determining how the agent should behave to achieve its objectives. On the other hand, reinforcement learning additionally learns these models based on the feedback the agent gets from the environment. This book provides a concise introduction to the use of MDPs for solving probabilistic planning problems, with an emphasis on the algorithmic perspective. It covers the whole spectrum of the field, from the basics to state-of-the-art optimal and approximation algorithms.We first describe the theoretical foundations of MDPs and the fundamental solution techniques for them.We then discuss modern optimal algorithms based on heuristic search and the use of structured representations. A major focus of the book is on the numerous approximation schemes for MDPs that have been developed in the AI literature. These include determinization-based approaches, sampling techniques, heuristic functions, dimensionality reduction, and hierarchical representations. Finally, we briefly introduce several extensions of the standard MDP classes that model and solve even more complex planning problems",
                "5. Symbolic algorithms -- 5.1 Algebraic decision diagrams -- 5.2 SPUDD: value iteration using ADDs -- 5.3 Symbolic LAO* -- 5.4 Other symbolic algorithms -- 5.5 Other symbolic representations -- 5.6 Approximations using symbolic approaches --"
            ],
            "dcterms:contributor": "Technische Informationsbibliothek (TIB)",
            "isPartOf": [
                "(collectioncode)ZDB-105-MCIA",
                "(collectioncode)ZDB-105-MCS"
            ],
            "issued": "2012",
            "language": "http://id.loc.gov/vocabulary/iso639-1/en",
            "license": "commercial licence",
            "medium": "rda:termList/RDACarrierType/1018",
            "volume": "# 17",
            "P30128": "Synthesis lectures on artificial intelligence and machine learning",
            "P60163": "San Rafael, Calif. (1537 Fourth Street, San Rafael, CA  94901 USA)"
        }
    ],
    "@id": "urn:x-arq:DefaultGraphNode",
    "@context": {
        "contributor": "http://purl.org/dc/elements/1.1/contributor",
        "volume": "http://purl.org/ontology/bibo/volume",
        "identifier": "http://purl.org/dc/elements/1.1/identifier",
        "isPartOf": "http://purl.org/dc/terms/isPartOf",
        "issued": "http://purl.org/dc/terms/issued",
        "publisher": "http://purl.org/dc/elements/1.1/publisher",
        "language": {
            "@id": "http://purl.org/dc/terms/language",
            "@type": "@id"
        },
        "abstract": "http://purl.org/dc/terms/abstract",
        "medium": {
            "@id": "http://purl.org/dc/terms/medium",
            "@type": "@id"
        },
        "creator": "http://purl.org/dc/elements/1.1/creator",
        "P1053": "http://iflastandards.info/ns/isbd/elements/P1053",
        "description": "http://purl.org/dc/elements/1.1/description",
        "P60163": "http://www.rdaregistry.info/Elements/u/#P60163",
        "subject": "http://purl.org/dc/elements/1.1/subject",
        "title": "http://purl.org/dc/elements/1.1/title",
        "license": "http://purl.org/dc/terms/license",
        "P30128": "http://www.rdaregistry.info/Elements/m/#P30128",
        "umbel": "http://umbel.org/umbel#",
        "rdau": "http://www.rdaregistry.info/Elements/u/#",
        "owl": "http://www.w3.org/2002/07/owl#",
        "dcterms": "http://purl.org/dc/terms/",
        "bibo": "http://purl.org/ontology/bibo/",
        "rdam": "http://www.rdaregistry.info/Elements/m/#",
        "gnd": "http://d-nb.info/gnd/",
        "isbd": "http://iflastandards.info/ns/isbd/elements/",
        "rda": "http://rdvocab.info/",
        "doi": "https://doi.org/"
    }
}