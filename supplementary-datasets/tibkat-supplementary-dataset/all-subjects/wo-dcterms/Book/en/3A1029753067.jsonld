{
    "@graph": [
        {
            "@id": "gnd:134050258",
            "sameAs": "Vorobeychik, Yevgeniy"
        },
        {
            "@id": "https://www.tib.eu/de/suchen/id/TIBKAT%3A1029753067",
            "@type": "bibo:Book",
            "P1053": "1 Online-Ressource (171 Seiten)",
            "creator": "Kantarcioglu, Murat",
            "description": [
                "Erworben aus Studienqualit\u00e4tsmitteln",
                "Campusweiter Zugriff (Universit\u00e4t Hannover) - Vervielf\u00e4ltigungen (z.B. Kopien, Downloads) sind nur von einzelnen Kapiteln oder Seiten und nur zum eigenen wissenschaftlichen Gebrauch erlaubt. Keine Weitergabe an Dritte. Kein systematisches Downloaden durch Robots."
            ],
            "identifier": [
                "(isbn13)9781681733968",
                "(doi)10.1007/978-3-031-01580-9",
                "(isbn13)9781681733982",
                "(firstid)GBV:1029753067",
                "(ppn)1029753067"
            ],
            "publisher": "Morgan & Claypool Publishers",
            "subject": [
                "Artificial intelligence.",
                "(classificationName=linseach:mapping)inf",
                "(classificationName=ddc)006.3",
                "Machine learning.",
                "Neural networks (Computer science)."
            ],
            "title": "Adversarial Machine Learning",
            "abstract": [
                "Intro -- List of Figures -- Preface -- Acknowledgments -- Introduction -- Machine Learning Preliminaries -- Supervised Learning -- Regression Learning -- Classification Learning -- PAC Learnability -- Supervised Learning in Adversarial Settings -- Unsupervised Learning -- Clustering -- Principal Component Analysis -- Matrix Completion -- Unsupervised Learning in Adversarial Settings -- Reinforcement Learning -- Reinforcement Learning in Adversarial Settings -- Bibliographic Notes -- Categories of Attacks on Machine Learning -- Attack Timing -- Information Available to the Attacker -- Attacker Goals -- Bibliographic Notes -- Attacks at Decision Time -- Examples of Evasion Attacks on Machine Learning Models -- Attacks on Anomaly Detection: Polymorphic Blending -- Attacks on PDF Malware Classifiers -- Modeling Decision-Time Attacks -- White-Box Decision-Time Attacks -- Attacks on Binary Classifiers: Adversarial Classifier Evasion -- Decision-Time Attacks on Multiclass Classifiers -- Decision-Time Attacks on Anomaly Detectors -- Decision-Time Attacks on Clustering Models -- Decision-Time Attacks on Regression Models -- Decision-Time Attacks on Reinforcement Learning -- Black-Box Decision-Time Attacks -- A Taxonomy of Black-Box Attacks -- Modeling Attacker Information Acquisition -- Attacking Using an Approximate Model -- Bibliographical Notes -- Defending Against Decision-Time Attacks -- Hardening Supervised Learning against Decision-Time Attacks -- Optimal Evasion-Robust Classification -- Optimal Evasion-Robust Sparse SVM -- Evasion-Robust SVM against Free-Range Attacks -- Evasion-Robust SVM against Restrained Attacks -- Evasion-Robust Classification on Unrestricted Feature Spaces -- Robustness to Adversarially Missing Features -- Approximately Hardening Classifiers against Decision-Time Attacks -- Relaxation Approaches",
                "General-Purpose Defense: Iterative Retraining -- Evasion-Robustness through Feature-Level Protection -- Decision Randomization -- Model -- Optimal Randomized Operational Use of Classification -- Evasion-Robust Regression -- Bibliographic Notes -- Data Poisoning Attacks -- Modeling Poisoning Attacks -- Poisoning Attacks on Binary Classification -- Label-Flipping Attacks -- Poison Insertion Attack on Kernel SVM -- Poisoning Attacks for Unsupervised Learning -- Poisoning Attacks on Clustering -- Poisoning Attacks on Anomaly Detection -- Poisoning Attack on Matrix Completion -- Attack Model -- Attacking Alternating Minimization -- Attacking Nuclear Norm Minimization -- Mimicking Normal User Behaviors -- A General Framework for Poisoning Attacks -- Black-Box Poisoning Attacks -- Bibliographic Notes -- Defending Against Data Poisoning -- Robust Learning through Data Sub-Sampling -- Robust Learning through Outlier Removal -- Robust Learning through Trimmed Optimization -- Robust Matrix Factorization -- Noise-Free Subspace Recovery -- Dealing with Noise -- Efficient Robust Subspace Recovery -- An Efficient Algorithm for Trimmed Optimization Problems -- Bibliographic Notes -- Attacking and Defending Deep Learning -- Attacking and Defending Deep Learning -- Neural Network Models -- Attacks on Deep Neural Networks: Adversarial Examples -- l_2-Norm Attacks -- l_-Norm Attacks -- l_0-Norm Attacks -- Attacks in the Physical World -- Black-Box Attacks -- Making Deep Learning Robust to Adversarial Examples -- Robust Optimization -- Retraining -- Distillation -- Bibliographic Notes -- The Road Ahead -- Beyond Robust Optimization -- Incomplete Information -- Confidence in Predictions -- Randomization -- Multiple Learners -- Models and Validation -- Bibliography -- Authors' Biographies -- Index -- Blank Page"
            ],
            "contributor": "Technische Informationsbibliothek (TIB)",
            "dcterms:creator": {
                "@id": "gnd:134050258"
            },
            "isPartOf": [
                "(collectioncode)ZDB-2-SEB",
                "(collectioncode)ZDB-2-SXSC",
                "(collectioncode)BSZ-2-SXSC-syc8",
                "(collectioncode)ZDB-105-MCS",
                "(collectioncode)BSZ-2-SXSC-mc10"
            ],
            "issued": "2018",
            "language": "http://id.loc.gov/vocabulary/iso639-1/en",
            "license": "commercial licence",
            "medium": "rda:termList/RDACarrierType/1018",
            "volume": "#38",
            "isLike": "doi:10.1007/978-3-031-01580-9",
            "P30128": "Synthesis Lectures on Artificial Intelligence and Machine Learning",
            "P60163": "San Rafael"
        }
    ],
    "@id": "urn:x-arq:DefaultGraphNode",
    "@context": {
        "contributor": "http://purl.org/dc/terms/contributor",
        "P1053": "http://iflastandards.info/ns/isbd/elements/P1053",
        "issued": "http://purl.org/dc/terms/issued",
        "subject": "http://purl.org/dc/elements/1.1/subject",
        "abstract": "http://purl.org/dc/terms/abstract",
        "identifier": "http://purl.org/dc/elements/1.1/identifier",
        "isLike": {
            "@id": "http://umbel.org/umbel#isLike",
            "@type": "@id"
        },
        "title": "http://purl.org/dc/elements/1.1/title",
        "P30128": "http://www.rdaregistry.info/Elements/m/#P30128",
        "medium": {
            "@id": "http://purl.org/dc/terms/medium",
            "@type": "@id"
        },
        "description": "http://purl.org/dc/elements/1.1/description",
        "license": "http://purl.org/dc/terms/license",
        "isPartOf": "http://purl.org/dc/terms/isPartOf",
        "volume": "http://purl.org/ontology/bibo/volume",
        "P60163": "http://www.rdaregistry.info/Elements/u/#P60163",
        "language": {
            "@id": "http://purl.org/dc/terms/language",
            "@type": "@id"
        },
        "creator": "http://purl.org/dc/elements/1.1/creator",
        "publisher": "http://purl.org/dc/elements/1.1/publisher",
        "sameAs": "http://www.w3.org/2002/07/owl#sameAs",
        "umbel": "http://umbel.org/umbel#",
        "rdau": "http://www.rdaregistry.info/Elements/u/#",
        "owl": "http://www.w3.org/2002/07/owl#",
        "dcterms": "http://purl.org/dc/terms/",
        "bibo": "http://purl.org/ontology/bibo/",
        "rdam": "http://www.rdaregistry.info/Elements/m/#",
        "gnd": "http://d-nb.info/gnd/",
        "isbd": "http://iflastandards.info/ns/isbd/elements/",
        "rda": "http://rdvocab.info/",
        "doi": "https://doi.org/"
    }
}