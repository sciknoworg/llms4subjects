{
    "@graph": [
        {
            "@id": "https://www.tib.eu/de/suchen/id/TIBKAT%3A1873164378",
            "@type": "bibo:Book",
            "P1053": "1 Online-Ressource(XVII, 287 p. 122 illus., 75 illus. in color.)",
            "creator": "Hu, Michael",
            "description": "Campusweiter Zugriff (Universit\u00e4t Hannover) - Vervielf\u00e4ltigungen (z.B. Kopien, Downloads) sind nur von einzelnen Kapiteln oder Seiten und nur zum eigenen wissenschaftlichen Gebrauch erlaubt. Keine Weitergabe an Dritte. Kein systematisches Downloaden durch Robots.",
            "identifier": [
                "(ppn)1873164378",
                "(isbn13)9781484296066",
                "(doi)10.1007/978-1-4842-9606-6",
                "(firstid)KEP:099428628"
            ],
            "publisher": "Apress",
            "subject": [
                "Machine learning.",
                "(classificationName=linseach:mapping)inf",
                "Python (Computer program language).",
                "Artificial intelligence.",
                "(classificationName=ddc)006.31"
            ],
            "title": "The Art of Reinforcement Learning : Fundamentals, Mathematics, and Implementations with Python",
            "abstract": [
                "Part I: Foundation -- Chapter 1: Introduction to Reinforcement Learning -- Chapter 2: Markov Decision Processes -- Chapter 3: Dynamic Programming -- Chapter 4: Monte Carlo Methods -- Chapter 5: Temporal Difference Learning -- Part II: Value Function Approximation -- Chapter 6: Linear Value Function Approximation -- Chapter 7: Nonlinear Value Function Approximation -- Chapter 8: Improvement to DQN -- Part III: Policy Approximation -- Chapter 9: Policy Gradient Methods -- Chapter 10: Problems with Continuous Action Space -- Chapter 11: Advanced Policy Gradient Methods -- Part IV: Advanced Topics -- Chapter 12: Distributed Reinforcement Learning -- Chapter 13: Curiosity-Driven Exploration -- Chapter 14: Planning with a Model \u2013 AlphaZero.",
                "Unlock the full potential of reinforcement learning (RL), a crucial subfield of Artificial Intelligence, with this comprehensive guide. This book provides a deep dive into RL's core concepts, mathematics, and practical algorithms, helping you to develop a thorough understanding of this cutting-edge technology. Beginning with an overview of fundamental concepts such as Markov decision processes, dynamic programming, Monte Carlo methods, and temporal difference learning, this book uses clear and concise examples to explain the basics of RL theory. The following section covers value function approximation, a critical technique in RL, and explores various policy approximations such as policy gradient methods and advanced algorithms like Proximal Policy Optimization (PPO). This book also delves into advanced topics, including distributed reinforcement learning, curiosity-driven exploration, and the famous AlphaZero algorithm, providing readers with a detailed account of these cutting-edge techniques. With a focus on explaining algorithms and the intuition behind them, The Art of Reinforcement Learning includes practical source code examples that you can use to implement RL algorithms. Upon completing this book, you will have a deep understanding of the concepts, mathematics, and algorithms behind reinforcement learning, making it an essential resource for AI practitioners, researchers, and students. You will: Grasp fundamental concepts and distinguishing features of reinforcement learning, including how it differs from other AI and non-interactive machine learning approaches Model problems as Markov decision processes, and how to evaluate and optimize policies using dynamic programming, Monte Carlo methods, and temporal difference learning Utilize techniques for approximating value functions and policies, including linear and nonlinear value function approximation and policy gradient methods Understand the architecture and advantages of distributed reinforcement learning Master the concept of curiosity-driven exploration and how it can be leveraged to improve reinforcement learning agents Explore the AlphaZero algorithm and how it was able to beat professional Go players."
            ],
            "contributor": "Technische Informationsbibliothek (TIB)",
            "isPartOf": [
                "(collectioncode)ZDB-2-SXPC",
                "(collectioncode)ZDB-2-SEB",
                "(collectioncode)ZDB-2-CWD"
            ],
            "issued": "2023",
            "language": "http://id.loc.gov/vocabulary/iso639-1/en",
            "license": "commercial licence",
            "medium": "rda:termList/RDACarrierType/1018",
            "isLike": "doi:10.1007/978-1-4842-9606-6",
            "P60163": "Berkeley, CA"
        }
    ],
    "@id": "urn:x-arq:DefaultGraphNode",
    "@context": {
        "identifier": "http://purl.org/dc/elements/1.1/identifier",
        "isPartOf": "http://purl.org/dc/terms/isPartOf",
        "license": "http://purl.org/dc/terms/license",
        "contributor": "http://purl.org/dc/terms/contributor",
        "language": {
            "@id": "http://purl.org/dc/terms/language",
            "@type": "@id"
        },
        "subject": "http://purl.org/dc/elements/1.1/subject",
        "medium": {
            "@id": "http://purl.org/dc/terms/medium",
            "@type": "@id"
        },
        "title": "http://purl.org/dc/elements/1.1/title",
        "description": "http://purl.org/dc/elements/1.1/description",
        "P60163": "http://www.rdaregistry.info/Elements/u/#P60163",
        "abstract": "http://purl.org/dc/terms/abstract",
        "creator": "http://purl.org/dc/elements/1.1/creator",
        "issued": "http://purl.org/dc/terms/issued",
        "publisher": "http://purl.org/dc/elements/1.1/publisher",
        "isLike": {
            "@id": "http://umbel.org/umbel#isLike",
            "@type": "@id"
        },
        "P1053": "http://iflastandards.info/ns/isbd/elements/P1053",
        "umbel": "http://umbel.org/umbel#",
        "rdau": "http://www.rdaregistry.info/Elements/u/#",
        "owl": "http://www.w3.org/2002/07/owl#",
        "dcterms": "http://purl.org/dc/terms/",
        "bibo": "http://purl.org/ontology/bibo/",
        "rdam": "http://www.rdaregistry.info/Elements/m/#",
        "gnd": "http://d-nb.info/gnd/",
        "isbd": "http://iflastandards.info/ns/isbd/elements/",
        "rda": "http://rdvocab.info/",
        "doi": "https://doi.org/"
    }
}